# Writing Bots with the FireFoundry SDK: A Comprehensive Guide

*Generated by Claude*

## 1. Introduction to Bot Architecture

The bot framework is the foundation of AI-powered functionality in the FireFoundry platform. Bots are the encapsulation of AI behaviors, handling interactions with large language models (LLMs) in a structured, reliable way. Understanding the bot architecture is essential for building effective applications with FireFoundry.

### 1.1 Core Concepts and Components

At their essence, FireFoundry bots follow a consistent architecture with these key components:

- **Bot**: The base class for all bots, providing core functionality for handling requests, interacting with LLMs, and processing responses.
- **BotRequest**: Encapsulates a request to a bot, including input, arguments, and contextual information.
- **BotResponse**: Represents the final output from a bot's execution.
- **BotTry**: Handles individual attempts at processing a request, with support for retries and error handling.
- **BotTryRequest**: Represents a single try within a bot's execution, maintaining state and context.
- **PromptGroup**: Collection of prompts that define the content sent to LLMs.
- **Dispatch Table**: Registry of tool call functions that can be invoked during bot execution.
- **BrokerClientPool**: Manages a pool of broker clients for efficient LLM communication.

The bot system is designed around a request-response pattern with robust error handling, retries, and tool call support:

```typescript
// Simplified example of the main bot execution flow
protected async *main(request: BotRequest<BTH>): AsyncGenerator<...> {
    let tries = 0;
    const max_tries = request.max_tries ?? this.max_tries;
    let err: FFError | undefined = undefined;
    
    while (tries < max_tries) {
        try {
            const thread_try_request = request.start_try(err);
            
            // Check for direct execution on first try
            const should_use_direct_execution = 
                tries === 0 && 
                this.should_use_direct_execution(request) &&
                this.direct_execution_handler !== undefined;
            
            let partial_iterator;
            if (should_use_direct_execution) {
                // Use direct execution to bypass LLM
                partial_iterator = this.create_direct_execution_try(thread_try_request)
                    .start(thread_try_request);
            } else {
                // Normal LLM-based execution
                partial_iterator = this.thread_try.start(thread_try_request);
            }
            
            // Forward all yields from the iterator
            while (true) {
                const result = await partial_iterator.next();
                if (result.done) {
                    return result.value;
                }
                yield result.value;
            }
        } catch (error) {
            // Capture the error for the next try
            err = error as FFError;
            yield { bot_name: this.name, type: 'ERROR', error: err };
        }
        tries++;
    }
    
    throw new FFError("max tries reached");
}
```

### 1.2 Bot Types and Hierarchies

The FireFoundry SDK provides several bot types designed for different purposes:

- **Bot**: The base class for all bots
- **StructuredDataBot**: Specializes in extracting structured data from LLM responses
- **BotCustomErrorHandling**: Adds sophisticated error handling capabilities
- **DirectExecutionBotTry**: Supports bypassing the LLM to execute code directly
- **BotChat**: Simplified bot for chat interactions

These bot types form a hierarchy that allows you to choose the right level of functionality for your needs:

```
Bot
├── StructuredDataBot
├── BotChat
├── BotCustomErrorHandling
└── (Custom bot implementations)
```

### 1.3 The Request-Response Flow with Tool Calls

Understanding the flow of data through the bot system is critical for effective implementation:

1. **Request Initiation**:
   - A `BotRequest` is created with input and arguments
   - Context is provided through the request's `context` property
   - Optional configuration like model selection criteria is specified
   - Tool call results from previous tries are available

2. **Bot Processing**:
   - The bot creates a `BotTry` to handle the request
   - Dispatch table is configured with available tool calls
   - The try renders prompts and sends them to the LLM
   - Tool calls are executed if requested by the LLM
   - The LLM response is processed through post-processing
   - Errors are handled with retries if necessary

3. **Tool Call Execution**:
   - LLM can request tool calls via the dispatch table
   - Tool functions are executed asynchronously
   - Results are added to the conversation context
   - Processing continues with tool results

4. **Response Generation**:
   - Processed results are returned as a `BotResponse`
   - Progress updates are streamed during processing
   - Partial results can be accumulated during execution

5. **Error Handling**:
   - Errors are captured and can be passed to subsequent tries
   - Specialized error handlers can process specific error types
   - InternalErrors trigger automatic retries
   - Error context is preserved for debugging

### 1.4 Broker Client Pool Architecture

The bot framework includes a sophisticated broker client pooling system for efficient resource management:

```typescript
export class BrokerClientPool {
    private all_clients: SimplifiedBrokerClient[] = [];
    private available_clients: SimplifiedBrokerClient[] = [];
    private capacity_source: CapacitySource;

    constructor(pool_size: number = 20) {
        this.capacity_source = new CapacitySource(pool_size);
        this.initialize_pool(pool_size);
    }

    public async acquire_client(): Promise<SimplifiedBrokerClient> {
        // Get next available client (FIFO)
        const client = this.available_clients[0];
        if (!client) {
            throw new Error("No available client despite having capacity");
        }
        return client;
    }

    public async release_client(client: SimplifiedBrokerClient): Promise<void> {
        // Mark client as available again
        this.available_clients.push(client);
    }
}
```

## 2. Basic Bot Implementation

Creating a basic bot involves implementing the core components required for LLM interactions.

### 2.1 Creating a Simple Bot

To create a simple bot, extend the `Bot` class and implement the required methods:

```typescript
import { 
    Bot, 
    BotPostprocessGenerator, 
    BotRequest, 
    BotTryRequest, 
    BrokerTextContent, 
    BotTypeHelper, 
    PromptGroup 
} from "@firebrandanalytics/ff_sdk";

// Define the prompt type helper for type safety
export type SIMPLE_PTH = PromptTypeHelper<string, {
    static: { company: string; },
    request: { query?: string; }
}>;

// Define the bot type helper for type safety
export type SIMPLE_BTH = BotTypeHelper<SIMPLE_PTH, string>;

export default class SimpleBot extends Bot<SIMPLE_BTH> {
    constructor() {
        super({
            name: "SimpleBot",
            base_prompt_group: simple_prompt_group, // Define this separately
            model_pool_name: "azure_completion_4o",
            static_args: { company: "FinanceIQ" },
            // Optional: Add dispatch table for tool calls
            dispatch_table: {
                calculate: {
                    func: async (request, args) => {
                        // Tool implementation
                        return args.a + args.b;
                    },
                    spec: {
                        name: "calculate",
                        description: "Add two numbers",
                        parameters: {
                            type: "object",
                            properties: {
                                a: { type: "number" },
                                b: { type: "number" }
                            },
                            required: ["a", "b"]
                        }
                    }
                }
            }
        });
    }

    override get_semantic_label_impl(request: BotTryRequest<SIMPLE_BTH>): string {
        return 'SimpleBotSemanticLabel';
    }

    override async *postprocess_generator(
        broker_content: BrokerTextContent,
        request?: BotTryRequest<SIMPLE_BTH>
    ): BotPostprocessGenerator<SIMPLE_BTH> {
        // Simple bots might just return the content directly
        return broker_content.content;
    }
}
```

### 2.2 Prompt Groups and Templates

Prompt groups organize the content sent to LLMs. They combine multiple prompts into a coherent structure:

```typescript
import { PromptGroup, PromptText, PromptInputText } from "@firebrandanalytics/ff_sdk";

// Create a prompt group with system instructions and user input
const simple_prompt_group = new PromptGroup<SIMPLE_PTH>([
    {
        name: 'system_instructions',
        prompt: new PromptText<SIMPLE_PTH>(
            'system',
            {},
            (request) => `You are an assistant for ${request.args.static.company}.
            Answer questions clearly and concisely.`
        )
    },
    {
        name: 'user_input',
        prompt: new PromptInputText<SIMPLE_PTH>({})
    }
]);
```

For more complex prompts, you can create custom prompt classes:

```typescript
import { Prompt, PromptTemplateSectionNode } from "@firebrandanalytics/ff_sdk";

export class CustomPrompt extends Prompt<CUSTOM_PTH> {
    constructor(args: CUSTOM_PTH['args']['static']) {
        super('system', args);
        this.add_section(this.get_Context_Section());
        this.add_section(this.get_Rules_Section());
        // Add more sections as needed
    }
    
    protected get_Context_Section(): PromptTemplateNode<CUSTOM_PTH> {
        return new PromptTemplateSectionNode<CUSTOM_PTH>({
            semantic_type: 'context',
            content: 'Context:',
            children: [
                `You are an assistant for ${this.static_args.company}.`,
                `Your task is to provide helpful responses.`
            ]
        });
    }
    
    protected get_Rules_Section(): PromptTemplateNode<CUSTOM_PTH> {
        // Implementation for rules section
        // ...
    }
}
```

### 2.3 Processing LLM Responses

The `postprocess_generator` method is where you transform LLM responses into structured data:

```typescript
override async *postprocess_generator(
    broker_content: BrokerTextContent,
    request?: BotTryRequest<MY_BTH>
): BotPostprocessGenerator<MY_BTH> {
    // For text extraction, you might just return the content
    return broker_content.content;
    
    // For JSON extraction, parse and validate:
    try {
        const json_code = extractJSON(broker_content.content);
        const json_object = JSON.parse(json_code);
        
        // Validate or transform the JSON here
        return json_object;
    } catch (error: any) {
        throw new FFError(`Invalid JSON structure: ${error.message}`);
    }
}
```

### 2.4 Error Handling

Basic error handling is built into the bot system through the try mechanism:

```typescript
// The Bot.main method handles retries automatically
while (tries < max_tries) {
    try {
        // Process the request
        // ...
    } catch (error) {
        // Capture the error for the next try
        err = error as FFError;
        yield { bot_name: this.name, type: 'ERROR', error: err };
    }
    tries++;
}
```

For more specialized error handling, you can add error-specific prompt groups:

```typescript
const error_prompt_group = new PromptGroup<ERROR_PTH>([
    {
        name: 'error_instructions',
        prompt: new PromptText<ERROR_PTH>(
            'system',
            {},
            (request) => `There was an error in the previous response: 
            ${request.input.message}
            
            Please fix the error and try again.`
        )
    }
]);
```

## 3. Tool Calls and Dispatch Tables

The bot framework supports tool calls through dispatch tables, allowing LLMs to invoke functions during processing.

### 3.1 Defining Tool Functions

Tool functions are registered in the bot's dispatch table:

```typescript
import { DispatchTable, ToolCallFunc } from "@firebrandanalytics/ff_sdk";

// Define tool function types
type CalculateArgs = { a: number; b: number; };
type CalculateResult = number;

// Create the dispatch table
const myDispatchTable: DispatchTable<MY_PTH, MY_OUTPUT> = {
    calculate: {
        func: async (request, args: CalculateArgs): Promise<CalculateResult> => {
            logger.detail('[Bot] Executing calculate tool', { args });
            return args.a + args.b;
        },
        spec: {
            name: "calculate",
            description: "Add two numbers together",
            parameters: {
                type: "object",
                properties: {
                    a: { type: "number", description: "First number" },
                    b: { type: "number", description: "Second number" }
                },
                required: ["a", "b"]
            }
        }
    },
    fetch_data: {
        func: async (request, args: { query: string }) => {
            // Access working memory through request
            const wmp = request.parent.context_provider.working_memory_provider;
            // Fetch and return data
            return { data: "fetched results" };
        },
        spec: {
            name: "fetch_data",
            description: "Fetch data based on query",
            parameters: {
                type: "object",
                properties: {
                    query: { type: "string", description: "Query string" }
                },
                required: ["query"]
            }
        }
    }
};
```

### 3.2 Registering the Dispatch Table

Register the dispatch table in your bot constructor:

```typescript
export default class MyBot extends Bot<MY_BTH> {
    constructor() {
        super({
            name: "MyBot",
            base_prompt_group: my_prompt_group,
            model_pool_name: "azure_completion_4o",
            static_args: {},
            dispatch_table: myDispatchTable // Register the dispatch table
        });
    }
}
```

### 3.3 Tool Call Execution Flow

When the LLM requests tool calls:

1. The bot's `handle_tool_calls` method is invoked
2. Tool functions are retrieved from the dispatch table
3. Functions are executed asynchronously
4. Results are added to the conversation context
5. Processing continues with the tool results

```typescript
protected async handle_tool_calls(
    request: BotTryRequest<T>,
    broker_response: BrokerResponse<T["broker_content_type"]> & {
        finish_reason: "tool_calls";
        tool_calls: BrokerToolCall[];
    }
): Promise<void> {
    const tool_calls = broker_response.tool_calls;
    const promises: Promise<{ id: string; value: any }>[] = [];

    for (const tool_call of tool_calls) {
        const tool_call_func = this.parent.get_tool_call_func(tool_call.function_name);
        if (tool_call_func) {
            const args = JSON.parse(tool_call.arguments as unknown as string);
            promises.push(
                tool_call_func(request, args)
                    .then((result) => ({ id: tool_call.id, value: result }))
                    .catch((error) => { throw { id: tool_call.id, error }; })
            );
            
            // Track tool call in request state
            request.state.tool_call_results[tool_call.id] = {
                func_name: tool_call.function_name,
                arguments: args,
            };
        }
    }

    const tool_call_results = await Promise.allSettled(promises);
    
    // Add results to conversation context
    for (const tool_call_result of tool_call_results) {
        if (tool_call_result.status === "fulfilled") {
            request.state.tool_call_results[tool_call_result.value.id].result = 
                tool_call_result.value.value;
            request.add_additional_message({
                role: "tool",
                tool_call_id: tool_call_result.value.id,
                content: JSON.stringify(tool_call_result.value.value, undefined, 2),
            });
        }
    }
}
```

## 4. Specialized Bot Types

The FireFoundry SDK includes specialized bot types for common patterns and needs.

### 4.1 StructuredDataBot

`StructuredDataBot` is designed for extracting structured data from LLM responses with schema validation:

```typescript
import { 
    StructuredDataBot, 
    StructuredDataBotConfig 
} from "@firebrandanalytics/ff_sdk";
import { z } from "zod";

// Define your output schema with Zod
export const MyOutputSchema = z.object({
    result: z.string(),
    confidence: z.number(),
    metadata: z.object({
        source: z.string(),
        timestamp: z.string()
    })
});

// Define the type helper
export type MY_BTH = BotTypeHelper<MY_PTH, z.infer<typeof MyOutputSchema>>;

export default class MyStructuredBot extends StructuredDataBot<
    typeof MyOutputSchema, 
    MY_BTH,
    MY_PTH
> {
    constructor() {
        const config: StructuredDataBotConfig<typeof MyOutputSchema, MY_PTH> = {
            name: "MyStructuredBot",
            schema: MyOutputSchema,
            schema_description: "Output with result and metadata",
            base_prompt_group: my_prompt_group,
            model_pool_name: "azure_completion_4o",
        };
        super(config);
    }

    override get_semantic_label_impl(request: BotTryRequest<MY_BTH>): string {
        return 'MyStructuredBotSemanticLabel';
    }
    
    // Optional: Add custom validation or processing
    protected override process_validated_data(data: z.infer<typeof MyOutputSchema>) {
        // Additional processing if needed
        return data;
    }
}
```

The `StructuredDataBot` handles JSON extraction and schema validation automatically, so you don't need to implement `postprocess_generator` unless you need custom processing.

### 4.2 BotChat

`BotChat` provides a simplified interface for chat-based interactions:

```typescript
import { BotChat } from "@firebrandanalytics/ff_sdk";

export class MyChatBot extends BotChat<MY_PAT> {
    constructor() {
        super({
            name: "MyChatBot",
            base_prompt_group: chat_system_prompt,
            static_args: { company: "FinanceIQ" },
            llm_options: { temperature: 0.7 }
        });
    }
}
```

### 4.3 Custom Bot Implementations

For specialized needs, you can create custom bot implementations:

```typescript
import { Bot, BotPostprocessGenerator } from "@firebrandanalytics/ff_sdk";

export default class SpecializedBot extends Bot<SPECIALIZED_BTH> {
    constructor() {
        super({
            name: "SpecializedBot",
            base_prompt_group: specialized_prompt_group,
            model_pool_name: "azure_completion_4o",
            static_args: {},
            // Add custom execution strategy if needed
            thread_try_factory: (parent) => new CustomBotTry({ parent })
        });
    }

    override async *postprocess_generator(
        broker_content: BrokerTextContent,
        request?: BotTryRequest<SPECIALIZED_BTH>
    ): BotPostprocessGenerator<SPECIALIZED_BTH> {
        // Specialized processing logic
        const processed_data = this.specialized_processing(broker_content.content);
        
        // You can yield progress updates during processing
        yield {
            type: "INTERNAL_UPDATE",
            internal_step: "processing",
            message: "Processed data",
            metadata: { stage: "processing_complete" },
            bot_name: this.name,
        };
        
        return processed_data;
    }
    
    private specialized_processing(content: string): any {
        // Custom processing logic
        // ...
    }
}
```

## 5. Advanced Bot Features

The FireFoundry bot framework includes several advanced features for complex scenarios.

### 5.1 Custom Error Handling with Error Classification

The `BotCustomErrorHandling` class provides specialized error handling capabilities with automatic error classification:

```typescript
import { 
    BotCustomErrorHandling, 
    BotCustomErrorHandlingDispatchTry,
    CompilerError,
    RuntimeError,
    SQLError,
    InternalError
} from "@firebrandanalytics/ff_sdk";

// Define error handling bot for compiler errors
export class CompilerErrorBot extends BotCustomErrorHandling<
    CODER_BTH,
    COMPILER_ERROR_BTH,
    'CompilerError',
    BotCustomErrorHandlingDispatchTry<CODER_BTH, any>
> {
    constructor(args: {
        name: string;
        parent: BotCustomErrorHandlingDispatchTry<CODER_BTH, any>;
        base_prompt_group: PromptGroup<COMPILER_ERROR_PTH>;
        static_args: COMPILER_ERROR_BTH['pth']['args']['static'];
    }) {
        super({
            ...args,
            model_pool_name: "azure_completion_4o",
        });
    }
    
    // Build a specialized request for fixing compiler errors
    async build_request(request: BotTryRequest<CODER_BTH>): Promise<BotRequest<COMPILER_ERROR_BTH>> {
        const typescript_code = await this.extractCodeFromPreviousTry(request);
        const error_message = request.error?.message || "Unknown compiler error";
        
        return new BotRequest<COMPILER_ERROR_BTH>({
            id: `compiler_error_fix_${Date.now()}`,
            args: {
                typescript_code,
                error_message,
                error_details: (request.error as CompilerError)?.details || {}
            },
            input: "Fix the compiler error in the TypeScript code",
            context: request.parent.context,
            model_selection_criteria: request.parent.model_selection_criteria
        });
    }
    
    // Merge the fixed code into the original response
    async merge_results(
        request: BotTryRequest<CODER_BTH>, 
        result: string
    ): Promise<BrokerResponse<CODER_BTH["broker_content_type"]>> {
        const original_code = await this.extractCodeFromPreviousTry(request);
        const original_broker_content = this.extractBrokerContent(request);
        
        return this.createMergedBrokerResponse(
            request,
            result,
            original_code,
            original_broker_content,
            'compiler error'
        );
    }
}
```

### 5.2 InternalError and Automatic Retries

The framework now includes `InternalError` for handling temporary/retryable failures:

```typescript
// InternalError is automatically retried
export class InternalError extends FFError {
    details: InternalErrorDetails;

    constructor(message: string, details: InternalErrorDetails = {}) {
        super(message);
        this.name = "InternalError";
        this.details = details;
    }
}

// Example usage in code execution with automatic retries
export const executeCodeSandboxWithRetries = async function* (
    runCodeArgs: ProcessCodeRequest,
    workingMemoryId: UUID,
    wmp: WorkingMemoryProvider,
    botName: string,
    maxRetries: number = 3
): BotPostprocessGenerator<CODER_BTH> {
    let retryCount = 0;
    
    while (true) {
        try {
            return yield* executeCodeSandbox(runCodeArgs, workingMemoryId, wmp, botName);
        } catch (error) {
            if (error instanceof InternalError && retryCount < maxRetries) {
                retryCount++;
                logger.detail(`[Bot] Caught InternalError, retrying (${retryCount}/${maxRetries})`);
                
                // Yield a retry progress update
                yield {
                    type: "INTERNAL_UPDATE",
                    internal_step: "postprocessing",
                    message: `Retrying after internal error (attempt ${retryCount}/${maxRetries})`,
                    metadata: {
                        stage: "retry",
                        retry_count: retryCount,
                        max_retries: maxRetries,
                        error_message: error.message
                    },
                    bot_name: botName,
                };
                
                // Short delay before retry
                await new Promise(resolve => setTimeout(resolve, 3000));
                continue;
            }
            
            // Not retryable or max retries reached
            throw error;
        }
    }
}
```

### 5.3 Direct Code Execution

The framework supports bypassing the LLM and directly executing code:

```typescript
export class CodeExecutionBot extends Bot<CODE_BTH> {
    constructor() {
        super({
            name: "CodeExecutionBot",
            base_prompt_group: code_prompt_group,
            model_pool_name: "azure_completion_4o",
            static_args: {},
            // Set up direct execution handlers
            direct_execution_handler: async function* (request) {
                return yield* this.handleDirectCodeExecution(request);
            },
            direct_execution_code_extractor: async (request) => {
                return this.extractCodeForDirectExecution(request);
            }
        });
    }

    // Direct execution handler function
    private async *handleDirectCodeExecution(
        request: BotTryRequest<CODE_BTH>
    ): BotPostprocessGenerator<CODE_BTH> {
        logger.detail('[Bot] Handling direct code execution');
        
        const directReusePath = request.parent.args?.direct_code_reuse_path as string;
        if (!directReusePath) {
            throw new FFError("No direct_code_reuse_path provided");
        }
        
        const wmp = request.parent.context_provider.working_memory_provider;
        const memory_manifest = await wmp.get_working_memory_manifest_rpc(
            request.parent.context.root_entity_node_dto.id
        );
        
        const workingMemoryId = getMemoryId(memory_manifest, directReusePath);
        if (!workingMemoryId) {
            throw new FFError(`Working memory path not found: ${directReusePath}`);
        }
        
        const content = await wmp.get_memory_content_rpc(workingMemoryId);
        
        yield {
            type: "INTERNAL_UPDATE",
            internal_step: "direct_execution",
            message: "Retrieved code from working memory",
            metadata: { stage: "code_retrieval" },
            bot_name: this.name,
        };
        
        // Execute the code and return results
        return yield* executeCodeSandbox(run_code_args, workingMemoryId, wmp, this.name);
    }

    // Determine when to use direct execution
    protected override should_use_direct_execution(request: BotRequest<CODE_BTH>): boolean {
        const args = request.args;
        if (args && typeof args === 'object' && 'direct_code_reuse_path' in args) {
            return !!args.direct_code_reuse_path;
        }
        return false;
    }
    
    // Extract code for error handlers
    private async extractCodeForDirectExecution(
        request: BotTryRequest<CODE_BTH>
    ): Promise<string> {
        const directReusePath = request.parent.args?.direct_code_reuse_path as string;
        if (directReusePath) {
            const wmp = request.parent.context_provider.working_memory_provider;
            // Retrieve and return the code
            const content = await wmp.get_memory_content_rpc(workingMemoryId);
            return stripModuleImports(content);
        }
        return "";
    }
}
```

### 5.4 Working with Memory

Bots can interact with the working memory system to store and retrieve data:

```typescript
// Store results in working memory
override async *postprocess_generator(
    broker_content: BrokerTextContent,
    request: BotTryRequest<DATA_MANIFEST_BTH>
): BotPostprocessGenerator<DATA_MANIFEST_BTH> {
    const json_code = extractJSON(broker_content.content);
    const json_object = JSON.parse(json_code);
    
    // Validate the JSON object against the schema
    const result = DataManifestOutputSchema.safeParse(json_object);
    
    if (!result.success) {
        throw new FFError(`Invalid JSON structure: ${result.error.message}`);
    }
    
    // Save results to working memory
    try {
        const wmp = request.parent.context_provider.working_memory_provider;
        const task_node = request.parent.context.prevailing_context_node_dto;
        
        const { workingMemoryId } = await wmp.insert_code_memory({
            entityNodeId: task_node.id,
            name: 'data_manifest.json',
            memoryType: 'data/json',
            description: 'Data manifest results from knowledge lookup',
            contentType: 'application/json',
            buffer: Buffer.from(JSON.stringify(result.data, null, 2)),
            metadata: {
                type: 'knowledge_lookup_result',
                component: 'data_manifest'
            }
        });
        
        logger.detail('[DataManifestBot] Saved data manifest to working memory', { workingMemoryId });
    } catch (error) {
        logger.error('[DataManifestBot] Failed to save data manifest to working memory', { error });
        // Don't throw here - we still want to return the results even if saving fails
    }
    
    return result.data;
}
```

To include working memory in prompts, use WMPromptGroup:

```typescript
const prompt_group = new WMPromptGroup<DATA_MANIFEST_PTH>(
    [
        // Prompt definitions
    ],
    {
        getDescription: (path: string) => {
            // Generate description based on path
            if (path.endsWith('.json')) {
                return 'JSON data from previous steps:';
            }
            return '';
        },
        filterPaths: (paths: string[]) => paths.filter(
            path => path.endsWith('.json')
        )
    }
);
```

### 5.5 Progress Tracking and Streaming

The bot framework supports real-time progress tracking through AsyncGenerators:

```typescript
override async *postprocess_generator(
    broker_content: BrokerTextContent,
    request: BotTryRequest<MY_BTH>
): BotPostprocessGenerator<MY_BTH> {
    // Yield progress updates during processing
    yield {
        type: "INTERNAL_UPDATE",
        internal_step: "phase_one",
        message: "Starting first phase of processing",
        metadata: { stage: "phase_one_started" },
        bot_name: this.name,
    };
    
    // First phase of processing
    const phase_one_results = await this.processPhaseOne(broker_content);
    
    yield {
        type: "PARTIAL_VALUE",
        content: { 
            name: "intermediate_result",
            result: phase_one_results 
        },
        bot_name: this.name
    };
    
    yield {
        type: "INTERNAL_UPDATE",
        internal_step: "phase_two",
        message: "Starting second phase of processing",
        metadata: { 
            stage: "phase_two_started",
            phase_one_complete: true 
        },
        bot_name: this.name,
    };
    
    // Second phase of processing
    const final_results = await this.processPhaseTwo(phase_one_results);
    
    yield {
        type: "INTERNAL_UPDATE",
        internal_step: "completed",
        message: "Processing complete",
        metadata: { stage: "all_phases_complete" },
        bot_name: this.name,
    };
    
    return final_results;
}
```

This enables UI components to show real-time progress indicators during processing.

## 6. Best Practices

### 6.1 Bot Design Principles

Follow these principles when designing bots for the FireFoundry SDK:

1. **Single Responsibility**: Each bot should have a clear, focused purpose
2. **Clear Input/Output Contracts**: Define explicit schemas for inputs and outputs
3. **Robust Error Handling**: Anticipate and handle failure cases, use InternalError for retryable failures
4. **Progress Transparency**: Provide clear progress updates during execution
5. **Statelessness**: Avoid storing state in bot instances; use working memory instead
6. **Tool Call Design**: Keep tool functions focused and well-documented
7. **Resource Management**: Properly manage broker client connections

Example of a well-designed bot:

```typescript
export default class NerBinningBot extends Bot<NER_BINNING_BTH> {
    constructor() {
        super({
            name: "NerBinningBot",
            base_prompt_group: ner_binning_prompt_group,
            model_pool_name: "azure_completion_4o",
            static_args: {},
            // Optional: Add tool calls for data processing
            dispatch_table: {
                process_entities: {
                    func: async (request, args) => {
                        // Process entities
                        return processedEntities;
                    },
                    spec: {
                        name: "process_entities",
                        description: "Process named entities",
                        parameters: { /* ... */ }
                    }
                }
            }
        });
    }

    override get_semantic_label_impl(request: BotTryRequest<NER_BINNING_BTH>): string {
        return 'NerBinningBotSemanticLabel';
    }

    override async *postprocess_generator(
        broker_content: BrokerTextContent,
        request: BotTryRequest<NER_BINNING_BTH>
    ): BotPostprocessGenerator<NER_BINNING_BTH> {
        // Extract and validate JSON
        let json_object: any;
        try {
            const json_code = extractJSON(broker_content.content);
            json_object = JSON.parse(json_code);
        } catch (error: any) {
            throw new FFError(`Invalid JSON structure: ${error.message}`);
        }

        // Validate against schema
        const result = NerBinningOutputSchema.safeParse(json_object);
        if (!result.success) {
            logger.error('[NerBinningBot] Schema validation failed', { error: result.error.message });
            throw new FFError(`Invalid JSON structure: ${result.error.message}`);
        }

        // Save results to working memory
        try {
            const wmp = request.parent.context_provider.working_memory_provider;
            const task_node = request.parent.context.prevailing_context_node_dto;

            const { workingMemoryId } = await wmp.insert_code_memory({
                entityNodeId: task_node.id,
                name: 'ner_binning.json',
                memoryType: 'data/json',
                description: 'NER binning results from knowledge lookup',
                contentType: 'application/json',
                buffer: Buffer.from(JSON.stringify(result.data, null, 2)),
                metadata: {
                    type: 'knowledge_lookup_result',
                    component: 'ner_binning'
                }
            });

            logger.detail('[NerBinningBot] Saved NER binning results to working memory', { workingMemoryId });
        } catch (error) {
            logger.error('[NerBinningBot] Failed to save NER binning results to working memory', { error });
            // Don't throw here - we still want to return the results even if saving fails
        }

        logger.detail('[NerBinningBot] Extracted result:', { result: result.data });
        return result.data;
    }
}
```

### 6.2 Error Recovery Strategies

Implement effective error recovery strategies:

1. **Progressive Retries**: Start with simple fixes, then try more complex strategies
2. **Error Classification**: Categorize errors for targeted handling (CompilerError, RuntimeError, SQLError, InternalError)
3. **Context Preservation**: Maintain context across retry attempts
4. **Fallback Mechanisms**: Provide graceful degradation paths
5. **Automatic Retries**: Use InternalError for temporary failures that should be retried

Example of the CoderErrorHandlingFactory pattern:

```typescript
export class CoderErrorHandlingFactory {
    public createErrorHandlingTryFactory(parent: Bot<CODER_BTH>) {
        // Create the dispatch try first (circular reference)
        let errorDispatchTry: BotCustomErrorHandlingDispatchTry<CODER_BTH, any>;
        
        // Create error handlers for different error types
        const compilerErrorBot = new CompilerErrorBot({
            name: "CompilerErrorHandler",
            parent: errorDispatchTry,
            base_prompt_group: compiler_error_prompt_group,
            static_args: {}
        });
        
        const runtimeErrorBot = new RuntimeErrorBot({
            name: "RuntimeErrorHandler",
            parent: errorDispatchTry,
            base_prompt_group: runtime_error_prompt_group,
            static_args: {}
        });
        
        const sqlErrorBot = new SQLErrorBot({
            name: "SQLErrorHandler",
            parent: errorDispatchTry,
            base_prompt_group: sql_error_prompt_group,
            static_args: {}
        });
        
        // Note: InternalError is handled automatically with retries
        // No need for a separate InternalErrorBot
        
        // Create the error dispatch try with the handlers
        errorDispatchTry = new BotCustomErrorHandlingDispatchTry(
            parent,
            {
                CompilerError: compilerErrorBot,
                RuntimeError: runtimeErrorBot,
                SQLError: sqlErrorBot
                // InternalError is not included - handled by retry logic
            },
            error_prompt_group
        );
        
        return errorDispatchTry;
    }
}
```

### 6.3 Testing and Debugging

Best practices for testing and debugging FireFoundry bots:

1. **Detailed Logging**: Use logger.detail for key decision points
2. **Progress Tracking**: Emit detailed progress updates during processing
3. **Error Context**: Include relevant context in error messages
4. **Semantic Labels**: Use meaningful semantic labels for debugging
5. **Partial Results**: Store intermediate results for inspection
6. **Tool Call Tracking**: Log tool call executions and results

Example of good logging and debugging:

```typescript
override async *postprocess_generator(
    broker_content: BrokerTextContent,
    request: BotTryRequest<MY_BTH>
): BotPostprocessGenerator<MY_BTH> {
    logger.detail('[MyBot] Starting postprocessing', { 
        broker_content_length: broker_content.content.length,
        request_id: request.id,
        try_index: request.try_index
    });
    
    try {
        const json_code = extractJSON(broker_content.content);
        logger.detail('[MyBot] Extracted JSON code', { json_code_length: json_code.length });
        
        const json_object = JSON.parse(json_code);
        logger.detail('[MyBot] Parsed JSON object', { keys: Object.keys(json_object) });
        
        // Check for tool call results if any were executed
        const tool_results = request.parent.get_tool_call_results();
        if (Object.keys(tool_results).length > 0) {
            logger.detail('[MyBot] Tool call results available', { 
                tool_calls: Object.keys(tool_results) 
            });
        }
        
        // Validate with schema
        const result = MyOutputSchema.safeParse(json_object);
        if (!result.success) {
            logger.error('[MyBot] Schema validation failed', { 
                error: result.error.message,
                validation_errors: result.error.errors 
            });
            throw new FFError(`Invalid JSON structure: ${result.error.message}`);
        }
        
        logger.detail('[MyBot] Successfully validated output', { result: result.data });
        return result.data;
    } catch (error) {
        logger.error('[MyBot] Error in postprocessing', { 
            error, 
            broker_content_sample: broker_content.content.substring(0, 200) 
        });
        throw error;
    }
}
```

### 6.4 Performance Considerations

Optimize bot performance with these techniques:

1. **Prompt Efficiency**: Keep prompts concise and focused
2. **Resource Management**: Broker client pool manages connections efficiently
3. **Caching**: Use working memory for caching results
4. **Request Batching**: Batch related requests when possible
5. **Progress Streaming**: Stream results to improve perceived performance
6. **Tool Call Optimization**: Design efficient tool functions
7. **Direct Execution**: Use direct execution to bypass LLM when appropriate

Example of optimizing a bot for performance:

```typescript
export default class OptimizedBot extends Bot<OPTIMIZED_BTH> {
    constructor() {
        super({
            name: "OptimizedBot",
            base_prompt_group: optimized_prompt_group,
            model_pool_name: "azure_completion_4o",
            static_args: {},
            llm_options: {
                max_tokens: 4000, // Limit token usage
                temperature: 0.2  // Lower temperature for consistency
            },
            // Enable direct execution for cached results
            direct_execution_handler: async function* (request) {
                // Check cache and return cached results if available
                const cached = await this.checkCache(request);
                if (cached) {
                    return cached;
                }
                // Otherwise proceed with normal execution
                throw new FFError("No cached result");
            }
        });
    }

    override async *postprocess_generator(
        broker_content: BrokerTextContent,
        request: BotTryRequest<OPTIMIZED_BTH>
    ): BotPostprocessGenerator<OPTIMIZED_BTH> {
        // Extract only what we need from broker content
        const json_code = extractJSON(broker_content.content);
        
        // Use a faster JSON parser if available
        const json_object = JSON.parse(json_code);
        
        // Stream partial results as they become available
        if (json_object.partial_results && json_object.partial_results.length > 0) {
            for (const partial of json_object.partial_results) {
                yield {
                    type: "PARTIAL_VALUE",
                    content: { 
                        name: "partial_result",
                        result: partial 
                    },
                    bot_name: this.name
                };
            }
        }
        
        // Process only what's needed for the final result
        const final_result = {
            summary: json_object.summary,
            key_metrics: json_object.key_metrics
            // Exclude unnecessary fields
        };
        
        // Cache the result for future use
        await this.cacheResult(request, final_result);
        
        return final_result;
    }
}
```

## 7. Real-world Examples

Let's examine several real-world examples from the FinanceIQ application to understand how bots are implemented in practice.

### 7.1 FactSheetBot

The FactSheetBot generates user-friendly explanations of AI query processing. It demonstrates how to structure a bot that produces formatted explanations.

```typescript
export default class FactSheetBot extends StructuredDataBot<typeof FactSheetOutputSchema, FACT_SHEET_BTH, FACT_SHEET_PROMPT_TYPE> {
  constructor() {
    // Create the WMPromptGroup configuration
    const klookup_files: Record<string, string> = {
      'data_manifest.json': 'Data tables used to answer the query:',
      'r_hierarchy.json': 'Corporate hierarchy information used:',
      'statement_hierarchy.json': 'Financial statement structure used:',
      'ner_binning.json': 'Entity classification results:',
      'ner_matching.json': 'Entity matching results:'
    }
    const wmConfig: WMConfig = {
      getDescription: (path: string) => {
        const fileName = path.split('/').pop() || '';
        return klookup_files[fileName] || `Content from ${fileName}:`;
      },
      filterPaths: (paths: string[]) => paths.filter(path => Object.keys(klookup_files).find(k => path.endsWith(k)))
    };
    
    // Define the prompts for the group
    const prompts = [
      {
        name: 'factsheet_bot',
        prompt: new FactSheetBotPrompt({
          app_name: "FinanceIQ Business Analyzer"
        })
      },
      {
        name: 'knowledge_tidbits',
        prompt: new MemoryTidbitPrompt<FACT_SHEET_PROMPT_TYPE>(
            "system",
            {},
            {
              preamble: `## Tidbits\n\nContext: The following tidbits detail the specific knowledge reported by the Coder as used to generate the solution:`
            },
            ['fact'],
            ['knowledge_used']
        )
      },
      {
        name: 'user_instruction',
        prompt: new PromptText<FACT_SHEET_PROMPT_TYPE>(
          'user',
          {},
          "Generate the fact sheet."
        )
      },
    ];

    // Create the prompt group with the new prompt structures
    const prompt_group = new WMPromptGroup<FACT_SHEET_PROMPT_TYPE>(
      prompts,
      wmConfig
    );

    super({
      name: "FactSheetBot",
      schema: FactSheetOutputSchema,
      schema_description: "A structured explanation of how the AI processed a query",
      app_name: "FinanceIQ Business Analyzer",
      base_prompt_group: prompt_group
    });

    logger.detail('[FactSheetBot] Initialized with schema and prompt group');
  }

  /**
   * Override the semantic label to provide a more specific description
   */
  override get_semantic_label_impl(_request: BotTryRequest<FACT_SHEET_BTH>): string {
    return 'FactSheetBotSemanticLabel';
  }
}
```

Key patterns from this example:
- Uses `StructuredDataBot` for schema validation
- Creates a custom `WMPromptGroup` with file-specific descriptions
- Includes memory tidbits for additional context
- Uses a focused user instruction

### 7.2 CoderBot with Advanced Features

The CoderBot is one of the most sophisticated examples, demonstrating advanced error handling, direct code execution, tool calls, and working memory integration.

```typescript
export default class CoderBot extends Bot<CODER_BTH> {
  constructor() {
    // Define a factory function for error handling
    const errorHandlingFactory = new CoderErrorHandlingFactory();
    
    // Define dispatch table for tool calls
    const coderDispatchTable: DispatchTable<CODER_PTH, CODER_OUTPUT> = {
      execute_sql: {
        func: async (request, args: { query: string }) => {
          // Execute SQL query
          const results = await executeSQLQuery(args.query);
          return results;
        },
        spec: {
          name: "execute_sql",
          description: "Execute a SQL query",
          parameters: {
            type: "object",
            properties: {
              query: { type: "string", description: "SQL query to execute" }
            },
            required: ["query"]
          }
        }
      },
      save_chart: {
        func: async (request, args: { chart_data: any, name: string }) => {
          // Save chart to working memory
          const wmp = request.parent.context_provider.working_memory_provider;
          const { workingMemoryId } = await wmp.insert_code_memory({
            entityNodeId: request.parent.context.prevailing_context_node_dto.id,
            name: `${args.name}.json`,
            memoryType: 'data/json',
            contentType: 'application/json',
            buffer: Buffer.from(JSON.stringify(args.chart_data, null, 2))
          });
          return { saved: true, workingMemoryId };
        },
        spec: {
          name: "save_chart",
          description: "Save chart data to working memory",
          parameters: {
            type: "object",
            properties: {
              chart_data: { type: "object", description: "Chart data to save" },
              name: { type: "string", description: "Chart name" }
            },
            required: ["chart_data", "name"]
          }
        }
      }
    };
    
    super({
      name: "CoderBot",
      base_prompt_group: coder_prompt_group,
      model_pool_name: "azure_completion_4o",
      static_args: {},
      thread_try_factory: (parent: Bot<CODER_BTH>) => 
        errorHandlingFactory.createErrorHandlingTryFactory(parent),
      max_tries: 5,
      dispatch_table: coderDispatchTable,
      direct_execution_handler: async function* (request) {
        return yield* handleDirectCodeExecution(request);
      },
      direct_execution_code_extractor: async (request) => {
        return extractCodeForDirectExecution(request);
      }
    });
  }

  /**
   * Determines if direct execution should be used for this request
   */
  protected override should_use_direct_execution(request: BotRequest<CODER_BTH>): boolean {
    const args = request.args;
    if (args && typeof args === 'object' && 'direct_code_reuse_path' in args) {
      return !!args.direct_code_reuse_path;
    }
    return false;
  }

  /**
   * Process LLM responses, extracting code and executing it
   */
  override async *postprocess_generator(
    broker_content: BrokerTextContent,
    request: BotTryRequest<CODER_BTH>
  ): BotPostprocessGenerator<CODER_BTH> {
    // Extract JSON metadata and TypeScript code
    // Upload code to working memory
    // Execute the code with automatic retries for InternalErrors
    // Save essential data to working memory
    // Return final output
    
    return yield* executeCodeSandboxWithRetries(
      run_code_args,
      workingMemoryId,
      wmp,
      this.name,
      3 // max retries for InternalError
    );
  }
}
```

Key patterns from this example:
- Custom error handling with specialized handlers for different error types
- Direct code execution capability for reusing existing code
- Tool calls for SQL execution and chart saving
- Progress tracking throughout the execution process
- Working memory integration for persistence
- Automatic retries for InternalError
- Structured output with metadata

### 7.3 Agent Bundle Integration

When integrating bots into Agent Bundles (formerly App Runners), consider:

```typescript
export class FinanceAnalyzerAgentBundle {
  private bots: Map<string, Bot<any>>;
  
  constructor() {
    this.bots = new Map();
    
    // Initialize bots with shared configuration
    this.bots.set('knowledge_lookup', new KnowledgeLookupBot());
    this.bots.set('coder', new CoderBot());
    this.bots.set('analyzer', new AnalyzerBot());
    this.bots.set('fact_sheet', new FactSheetBot());
  }
  
  async execute(query: string, context: Context): Promise<AnalysisResult> {
    // Execute knowledge lookup
    const knowledgeResult = await this.bots.get('knowledge_lookup')!.run(
      new BotRequest({
        input: query,
        args: { query },
        context
      })
    );
    
    // Execute coder with knowledge results
    const coderResult = await this.bots.get('coder')!.run(
      new BotRequest({
        input: query,
        args: { 
          knowledge_lookup_response: knowledgeResult.output,
          // Enable direct execution if code exists
          direct_code_reuse_path: await this.checkForExistingCode(query)
        },
        context
      })
    );
    
    // Generate analysis
    const analyzerResult = await this.bots.get('analyzer')!.run(
      new BotRequest({
        input: query,
        args: { coder_output: coderResult.output },
        context
      })
    );
    
    // Generate fact sheet
    const factSheetResult = await this.bots.get('fact_sheet')!.run(
      new BotRequest({
        input: query,
        args: {},
        context
      })
    );
    
    return {
      analysis: analyzerResult.output,
      factSheet: factSheetResult.output,
      charts: coderResult.output.chart_array
    };
  }
}
```

### 7.4 Common Bot Workflows

Several common bot workflows emerge from these examples:

**Data Processing Workflow**:
1. Extract structured data from LLM response
2. Validate against schema
3. Execute tool calls if needed
4. Save results to working memory
5. Return validated data

**Code Generation and Execution Workflow**:
1. Check for direct execution possibility
2. Extract code and metadata from LLM response (or retrieve from memory)
3. Save code to working memory
4. Execute code with error handling and automatic retries
5. Save execution results to working memory
6. Return processed results

**Entity Matching Workflow**:
1. Process input data to identify entities
2. Use tool calls for data retrieval
3. Match entities against known sources
4. Save matches as memory tidbits
5. Return matching results with confidence scores

**Question Answering Workflow**:
1. Process question input
2. Retrieve relevant context from working memory
3. Execute tool calls for additional data
4. Generate answer with supporting evidence
5. Return formatted response with citations

These workflows can be combined and extended to create sophisticated AI-powered applications.

## 8. Conclusion

The FireFoundry SDK's bot framework provides a powerful foundation for building AI-powered applications. Its key strengths include:

1. **Robust Architecture**: The separation of bots, requests, and tries enables sophisticated processing with error handling
2. **Type Safety**: Comprehensive TypeScript type helpers ensure type safety throughout the system
3. **Tool Call Support**: Dispatch tables enable LLMs to invoke functions during processing
4. **Streaming Progress**: Real-time progress updates provide transparency during processing
5. **Working Memory Integration**: Seamless integration with the working memory system for persistence
6. **Advanced Error Handling**: Specialized error handlers for different error types, with automatic retries for InternalError
7. **Direct Execution**: Support for bypassing the LLM to execute code directly
8. **Resource Management**: Broker client pooling for efficient LLM communication
9. **Agent Bundle Integration**: Bots work seamlessly within Agent Bundles for complex workflows

By following the patterns and best practices in this guide, you can create sophisticated, reliable bots that leverage the power of large language models while maintaining the structure and reliability needed for enterprise applications.

For more detailed information on specific components or advanced use cases, refer to the FireFoundry SDK documentation and examples.
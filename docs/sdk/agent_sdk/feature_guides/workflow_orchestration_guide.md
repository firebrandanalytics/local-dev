# Multi-Step Workflow Orchestration Guide

*Generated by Claude*

## 1. Introduction to Workflow Orchestration

Workflow orchestration in FireFoundry involves creating runnable entities that coordinate and execute other runnable entities in sequence, conditionally, or in parallel. This pattern enables you to build complex, multi-step business processes while maintaining clean separation of concerns and automatic state persistence.

### What is Workflow Orchestration?

A workflow orchestrator is a runnable entity that:
- **Coordinates multiple steps** - Creates and manages other runnable entities
- **Manages data flow** - Passes outputs from one step as inputs to the next
- **Handles business logic** - Makes decisions about which steps to execute and when
- **Provides progress tracking** - Reports status throughout the entire process
- **Maintains state** - Automatically persists workflow progress for resumability

### When to Use Orchestration

Consider workflow orchestration when you need to:
- **Process data through multiple stages** - Document analysis, content generation, data transformation
- **Coordinate AI and human tasks** - Mixed automated and manual processing
- **Handle complex business logic** - Conditional processing, approval workflows, quality gates
- **Manage long-running processes** - Tasks that may take minutes, hours, or days
- **Ensure process visibility** - Track progress through multi-step operations

### Basic Benefits

- **State Persistence** - Workflows can be paused and resumed automatically
- **Progress Tracking** - Real-time updates on workflow execution status
- **Resumability** - Continue from where you left off after system restarts
- **Clear Separation** - Each step has a single, well-defined responsibility
- **Extensibility** - Easy to add, modify, or reorder steps

## 2. Basic Linear Workflows

The simplest workflow pattern is linear execution: Step A, then Step B, then Step C. Each step's output becomes the input for the next step.

### 2.1 Simple Sequential Execution (A → B → C)

Here's the basic pattern for a linear workflow:

```typescript
import {
  RunnableEntityClass,
  RunnableEntityDecorator,
  RunnableEntityTypeHelper,
  EntityNodeTypeHelper,
  AddInterface
} from '@firebrandanalytics/ff-agent-sdk';

interface DocumentWorkflowData {
  documentText: string;
  outputFormat: 'summary' | 'analysis' | 'report';
}

type WORKFLOW_OUTPUT = {
  extractedText: string;
  analysis: string;
  formattedReport: string;
  processingTime: number;
};

@RunnableEntityDecorator({
  generalType: "DocumentWorkflow",
  specificType: "DocumentWorkflow",
  allowedConnections: {
    'Calls': ['TextExtractorStep', 'AnalysisStep', 'FormatterStep']
  }
})
export class DocumentWorkflow extends AddInterface<
  typeof RunnableEntityClass<any>,
  RunnableEntityClass<any>
>(RunnableEntityClass) {

  protected override async *run_impl(): AsyncGenerator<any, WORKFLOW_OUTPUT, never> {
    const startTime = Date.now();
    const dto = await this.get_dto();
    const { documentText, outputFormat } = dto.data;

    // Step A: Extract Text
    const textExtractor = await this.appendOrRetrieveCall(
      TextExtractorStep,
      "text_extraction_1",
      { input: documentText }
    );
    const extractedText = yield* await textExtractor.start();

    // Step B: Analyze Text
    const analyzer = await this.appendOrRetrieveCall(
      AnalysisStep,
      "analysis_1", 
      { 
        input: extractedText.cleanText,
        analysisType: outputFormat
      }
    );
    const analysis = yield* await analyzer.start();

    // Step C: Format Report
    const formatter = await this.appendOrRetrieveCall(
      FormatterStep,
      "formatting_1",
      {
        input: {
          originalText: extractedText.cleanText,
          analysis: analysis.insights,
          format: outputFormat
        }
      }
    );
    const formattedReport = yield* await formatter.start();

    const processingTime = Date.now() - startTime;

    return {
      extractedText: extractedText.cleanText,
      analysis: analysis.insights,
      formattedReport: formattedReport.document,
      processingTime
    };
  }
}
```

### Key Patterns in Linear Workflows

**The `appendOrRetrieveCall` Pattern**
```typescript
const stepEntity = await this.appendOrRetrieveCall(
  StepClass,           // The entity class to create
  "unique_step_name",  // Unique identifier for this step instance
  { input: data }      // Data to pass to the step
);
```

This method:
- **Creates the step entity** if it doesn't exist
- **Retrieves the existing entity** if it already exists (idempotent)
- **Returns the entity instance** ready for execution

**Using `yield*` for Execution**
```typescript
const result = yield* await stepEntity.start();
```

The `yield*` pattern:
- **Delegates to the child entity's generator** - Forwards all progress updates
- **Maintains workflow state** - Parent workflow tracks progress of child steps  
- **Returns the final result** when the child completes

### 2.2 Data Flow Between Steps

The key to effective linear workflows is designing clean data flow between steps:

```typescript
// Step A produces structured output
const extractionResult = yield* await textExtractor.start();
// extractionResult = { 
//   cleanText: "processed text...",
//   metadata: { wordCount: 150, language: "en" }
// }

// Step B consumes Step A's output and produces its own
const analysisResult = yield* await analyzer.start();
// analysisResult = {
//   insights: ["key point 1", "key point 2"],
//   sentiment: "positive",
//   topics: ["business", "technology"]
// }

// Step C combines previous outputs
const finalResult = yield* await formatter.start();
// finalResult = {
//   document: "<formatted HTML or PDF>",
//   summary: "Brief overview...",
//   metadata: { pages: 3, sections: 5 }
// }
```

**Data Transformation Patterns**

Sometimes you need to transform data between steps:

```typescript
// Transform Step A output for Step B input
const stepBInput = {
  textToAnalyze: extractionResult.cleanText,
  options: {
    includeTopics: dto.data.includeTopicAnalysis,
    language: extractionResult.metadata.language
  }
};

const analyzer = await this.appendOrRetrieveCall(
  AnalysisStep,
  "analysis_1",
  stepBInput
);
```

### 2.3 Combining Multiple Outputs

Your workflow's final output often combines results from multiple steps:

```typescript
// Accumulate results throughout the workflow
const workflowResults = {
  // Raw data from Step A
  originalWordCount: extractionResult.metadata.wordCount,
  language: extractionResult.metadata.language,
  
  // Analysis from Step B  
  keyInsights: analysisResult.insights,
  sentiment: analysisResult.sentiment,
  topics: analysisResult.topics,
  
  // Final deliverable from Step C
  formattedDocument: finalResult.document,
  documentMetadata: finalResult.metadata,
  
  // Workflow-level metadata
  processingTime: Date.now() - startTime,
  stepsCompleted: 3,
  success: true
};

return workflowResults;
```

**Result Structure Design**

Design your output schema to be useful for consumers:

```typescript
type WorkflowOutput = {
  // Primary deliverable - what the user wants
  deliverable: {
    document: string;
    format: string;
    downloadUrl?: string;
  };
  
  // Supporting information - useful for debugging/analysis
  analysis: {
    insights: string[];
    sentiment: string;
    topics: string[];
  };
  
  // Processing metadata - useful for monitoring
  metadata: {
    processingTimeMs: number;
    stepsExecuted: number;
    inputSize: number;
    outputSize: number;
  };
  
  // Status information
  success: boolean;
  errors?: string[];
};
```

## 3. Conditional Orchestration

Real workflows often need to make decisions about which steps to execute based on input data or the results of previous steps.

### 3.1 Input-Based Conditionals

Choose different workflow paths based on the initial input:

```typescript
protected override async *run_impl(): AsyncGenerator<any, WORKFLOW_OUTPUT, never> {
  const dto = await this.get_dto();
  const { documentType, processingMode, userPreferences } = dto.data;

  // Different workflows based on document type
  if (documentType === 'legal') {
    return yield* this.processLegalDocument(dto.data);
  } else if (documentType === 'financial') {
    return yield* this.processFinancialDocument(dto.data);
  } else {
    return yield* this.processStandardDocument(dto.data);
  }
}

private async *processLegalDocument(data: any): AsyncGenerator<any, WORKFLOW_OUTPUT, never> {
  // Legal documents need compliance checking
  const complianceCheck = await this.appendOrRetrieveCall(
    ComplianceCheckStep,
    "compliance_1",
    { document: data.documentText }
  );
  const complianceResult = yield* await complianceCheck.start();
  
  if (!complianceResult.passed) {
    return {
      success: false,
      error: "Document failed compliance check",
      issues: complianceResult.issues
    };
  }
  
  // Continue with standard processing...
  return yield* this.processStandardDocument(data);
}
```

**Business Logic Conditions**

```typescript
// Branch based on user type or permissions
if (dto.data.userRole === 'admin') {
  // Admin users get detailed analysis
  const detailedAnalyzer = await this.appendOrRetrieveCall(
    DetailedAnalysisStep,
    "detailed_analysis",
    { input: extractedText, includeConfidential: true }
  );
  analysisResult = yield* await detailedAnalyzer.start();
} else {
  // Regular users get basic analysis
  const basicAnalyzer = await this.appendOrRetrieveCall(
    BasicAnalysisStep,
    "basic_analysis", 
    { input: extractedText, includeConfidential: false }
  );
  analysisResult = yield* await basicAnalyzer.start();
}

// Branch based on data size
if (dto.data.documentText.length > 100000) {
  // Large documents need chunked processing
  const chunkProcessor = await this.appendOrRetrieveCall(
    ChunkProcessorStep,
    "chunk_processor",
    { input: dto.data.documentText, chunkSize: 10000 }
  );
  processedText = yield* await chunkProcessor.start();
} else {
  // Small documents can be processed directly
  const directProcessor = await this.appendOrRetrieveCall(
    DirectProcessorStep,
    "direct_processor",
    { input: dto.data.documentText }
  );
  processedText = yield* await directProcessor.start();
}
```

### 3.2 Result-Based Conditionals

Make decisions based on the results of previous steps:

```typescript
// Step A: Initial Analysis
const initialAnalyzer = await this.appendOrRetrieveCall(
  InitialAnalysisStep,
  "initial_analysis",
  { input: dto.data.documentText }
);
const initialResult = yield* await initialAnalyzer.start();

// Decision point: Choose next step based on quality score
let finalResult;

if (initialResult.qualityScore > 0.8) {
  // High quality - proceed with fast processing
  const quickProcessor = await this.appendOrRetrieveCall(
    QuickProcessorStep,
    "quick_processing",
    { input: initialResult.processedText }
  );
  finalResult = yield* await quickProcessor.start();
  
} else if (initialResult.qualityScore > 0.5) {
  // Medium quality - use standard processing
  const standardProcessor = await this.appendOrRetrieveCall(
    StandardProcessorStep,
    "standard_processing",
    { input: initialResult.processedText }
  );
  finalResult = yield* await standardProcessor.start();
  
} else {
  // Low quality - needs enhanced processing
  const enhancedProcessor = await this.appendOrRetrieveCall(
    EnhancedProcessorStep,
    "enhanced_processing",
    { 
      input: initialResult.processedText,
      issues: initialResult.detectedIssues,
      enhancementStrategies: initialResult.recommendedStrategies
    }
  );
  finalResult = yield* await enhancedProcessor.start();
}
```

**Quality Gates and Validation**

Use previous results to validate whether to continue:

```typescript
// Step 1: Data validation
const validator = await this.appendOrRetrieveCall(
  DataValidatorStep,
  "validation",
  { input: dto.data }
);
const validationResult = yield* await validator.start();

// Quality gate: Only continue if data is valid
if (!validationResult.isValid) {
  return {
    success: false,
    error: "Input data validation failed",
    validationErrors: validationResult.errors,
    suggestions: validationResult.suggestions
  };
}

// Step 2: Processing (only if validation passed)
const processor = await this.appendOrRetrieveCall(
  DataProcessorStep,
  "processing",
  { 
    input: validationResult.cleanedData,
    validationMetadata: validationResult.metadata
  }
);
const processingResult = yield* await processor.start();

// Quality gate: Check processing quality
if (processingResult.confidence < 0.7) {
  // Low confidence - run additional verification step
  const verifier = await this.appendOrRetrieveCall(
    VerificationStep,
    "verification",
    { 
      originalInput: dto.data,
      processedResult: processingResult,
      confidenceThreshold: 0.7
    }
  );
  const verifiedResult = yield* await verifier.start();
  
  return {
    success: true,
    result: verifiedResult.enhancedResult,
    confidence: verifiedResult.finalConfidence,
    requiredVerification: true
  };
}

// High confidence - return directly
return {
  success: true,
  result: processingResult.result,
  confidence: processingResult.confidence,
  requiredVerification: false
};
```

## 4. Loop Patterns

Loops in workflow orchestration handle repetitive processing, retry logic, and iterative improvement patterns.

### 4.1 Basic Loop Mechanics

**Counter-Based Loops**

Process a fixed number of iterations:

```typescript
protected override async *run_impl(): AsyncGenerator<any, WORKFLOW_OUTPUT, never> {
  const dto = await this.get_dto();
  const iterations = dto.data.iterations || 3;
  const results = [];

  for (let i = 0; i < iterations; i++) {
    const processor = await this.appendOrRetrieveCall(
      IterativeProcessorStep,
      `iteration_${i}`,
      { 
        input: dto.data.baseInput,
        iteration: i,
        previousResults: results
      }
    );
    
    const iterationResult = yield* await processor.start();
    results.push(iterationResult);
    
    // Yield progress update
    yield {
      type: "INTERNAL_UPDATE",
      message: `Completed iteration ${i + 1} of ${iterations}`,
      metadata: { iteration: i, totalIterations: iterations }
    };
  }

  return {
    success: true,
    iterations: results.length,
    results: results,
    finalResult: results[results.length - 1]
  };
}
```

**Condition-Based Loops**

Continue until some criteria is met:

```typescript
protected override async *run_impl(): AsyncGenerator<any, WORKFLOW_OUTPUT, never> {
  const dto = await this.get_dto();
  let attempts = 0;
  let result = null;
  const maxAttempts = dto.data.maxAttempts || 5;
  const targetAccuracy = dto.data.targetAccuracy || 0.9;

  while (attempts < maxAttempts) {
    const processor = await this.appendOrRetrieveCall(
      OptimizationStep,
      `attempt_${attempts}`,
      { 
        input: dto.data.baseInput,
        attempt: attempts,
        previousResult: result,
        targetAccuracy: targetAccuracy
      }
    );
    
    result = yield* await processor.start();
    attempts++;
    
    // Check if we've reached our target
    if (result.accuracy >= targetAccuracy) {
      yield {
        type: "INTERNAL_UPDATE", 
        message: `Target accuracy ${targetAccuracy} reached after ${attempts} attempts`,
        metadata: { 
          attempts: attempts,
          finalAccuracy: result.accuracy,
          targetReached: true
        }
      };
      break;
    }
    
    yield {
      type: "INTERNAL_UPDATE",
      message: `Attempt ${attempts}: accuracy ${result.accuracy}, target ${targetAccuracy}`,
      metadata: { 
        attempts: attempts,
        currentAccuracy: result.accuracy,
        targetAccuracy: targetAccuracy
      }
    };
  }

  return {
    success: result?.accuracy >= targetAccuracy,
    attempts: attempts,
    finalAccuracy: result?.accuracy || 0,
    targetReached: result?.accuracy >= targetAccuracy,
    result: result
  };
}
```

**Collection Processing**

Process arrays or collections of items:

```typescript
protected override async *run_impl(): AsyncGenerator<any, WORKFLOW_OUTPUT, never> {
  const dto = await this.get_dto();
  const items = dto.data.itemsToProcess;
  const results = [];
  const errors = [];

  for (let i = 0; i < items.length; i++) {
    try {
      const itemProcessor = await this.appendOrRetrieveCall(
        ItemProcessorStep,
        `item_${i}`,
        { 
          item: items[i],
          index: i,
          totalItems: items.length
        }
      );
      
      const itemResult = yield* await itemProcessor.start();
      results.push({
        index: i,
        item: items[i],
        result: itemResult,
        success: true
      });
      
      yield {
        type: "INTERNAL_UPDATE",
        message: `Processed item ${i + 1} of ${items.length}`,
        metadata: { 
          itemIndex: i,
          totalItems: items.length,
          successCount: results.length,
          errorCount: errors.length
        }
      };
      
    } catch (error) {
      errors.push({
        index: i,
        item: items[i],
        error: error.message,
        success: false
      });
      
      // Continue processing other items
      continue;
    }
  }

  return {
    success: errors.length === 0,
    totalItems: items.length,
    successfulItems: results.length,
    failedItems: errors.length,
    results: results,
    errors: errors,
    successRate: results.length / items.length
  };
}
```

### 4.2 Common Loop Use Cases

**Retry Patterns**

Attempt operations until success, with intelligent backoff:

```typescript
private async *retryWithBackoff<T>(
  stepClass: any,
  stepData: any,
  maxRetries: number = 3
): AsyncGenerator<any, T, never> {
  let lastError = null;
  
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const processor = await this.appendOrRetrieveCall(
        stepClass,
        `retry_${attempt}`,
        {
          ...stepData,
          attempt: attempt,
          isRetry: attempt > 0,
          previousError: lastError
        }
      );
      
      const result = yield* await processor.start();
      
      // Success - return immediately
      yield {
        type: "INTERNAL_UPDATE",
        message: `Operation succeeded on attempt ${attempt + 1}`,
        metadata: { 
          attempt: attempt,
          success: true,
          retriesUsed: attempt
        }
      };
      
      return result;
      
    } catch (error) {
      lastError = error;
      
      if (attempt === maxRetries - 1) {
        // Final attempt failed
        throw new Error(`Operation failed after ${maxRetries} attempts. Last error: ${error.message}`);
      }
      
      // Wait before retry (exponential backoff)
      const waitTime = Math.pow(2, attempt) * 1000; // 1s, 2s, 4s, etc.
      yield {
        type: "INTERNAL_UPDATE",
        message: `Attempt ${attempt + 1} failed, retrying in ${waitTime}ms`,
        metadata: { 
          attempt: attempt,
          error: error.message,
          waitTime: waitTime,
          retriesRemaining: maxRetries - attempt - 1
        }
      };
      
      await new Promise(resolve => setTimeout(resolve, waitTime));
    }
  }
}
```

**Batch Processing**

Handle large datasets by processing in manageable chunks:

```typescript
protected override async *run_impl(): AsyncGenerator<any, WORKFLOW_OUTPUT, never> {
  const dto = await this.get_dto();
  const items = dto.data.items;
  const batchSize = dto.data.batchSize || 10;
  const batches = [];
  
  // Split into batches
  for (let i = 0; i < items.length; i += batchSize) {
    batches.push(items.slice(i, i + batchSize));
  }
  
  const allResults = [];
  
  for (let batchIndex = 0; batchIndex < batches.length; batchIndex++) {
    const batch = batches[batchIndex];
    
    const batchProcessor = await this.appendOrRetrieveCall(
      BatchProcessorStep,
      `batch_${batchIndex}`,
      {
        items: batch,
        batchIndex: batchIndex,
        totalBatches: batches.length,
        batchSize: batchSize
      }
    );
    
    const batchResult = yield* await batchProcessor.start();
    allResults.push(...batchResult.processedItems);
    
    yield {
      type: "INTERNAL_UPDATE",
      message: `Completed batch ${batchIndex + 1} of ${batches.length}`,
      metadata: {
        batchIndex: batchIndex,
        totalBatches: batches.length,
        itemsProcessed: allResults.length,
        totalItems: items.length
      }
    };
  }
  
  return {
    success: true,
    totalItems: items.length,
    batchesProcessed: batches.length,
    results: allResults
  };
}
```

**Convergence Loops**

Iterate until results stabilize or improve:

```typescript
protected override async *run_impl(): AsyncGenerator<any, WORKFLOW_OUTPUT, never> {
  const dto = await this.get_dto();
  let previousScore = 0;
  let currentScore = 0;
  let iteration = 0;
  const maxIterations = dto.data.maxIterations || 10;
  const convergenceThreshold = dto.data.convergenceThreshold || 0.01;
  
  const results = [];
  
  do {
    const optimizer = await this.appendOrRetrieveCall(
      OptimizationStep,
      `optimization_${iteration}`,
      {
        input: dto.data.baseData,
        iteration: iteration,
        previousScore: previousScore,
        previousResults: results
      }
    );
    
    const iterationResult = yield* await optimizer.start();
    previousScore = currentScore;
    currentScore = iterationResult.score;
    results.push(iterationResult);
    iteration++;
    
    const improvement = currentScore - previousScore;
    const converged = iteration > 1 && Math.abs(improvement) < convergenceThreshold;
    
    yield {
      type: "INTERNAL_UPDATE",
      message: `Iteration ${iteration}: score ${currentScore.toFixed(3)}, improvement ${improvement.toFixed(3)}`,
      metadata: {
        iteration: iteration,
        currentScore: currentScore,
        previousScore: previousScore,
        improvement: improvement,
        converged: converged
      }
    };
    
    if (converged) {
      yield {
        type: "INTERNAL_UPDATE",
        message: `Converged after ${iteration} iterations (improvement ${improvement.toFixed(3)} < ${convergenceThreshold})`,
        metadata: { 
          converged: true,
          iterations: iteration,
          finalScore: currentScore
        }
      };
      break;
    }
    
  } while (iteration < maxIterations);
  
  return {
    success: true,
    iterations: iteration,
    finalScore: currentScore,
    converged: iteration < maxIterations,
    improvement: currentScore - (results[0]?.score || 0),
    results: results
  };
}
```

## 5. Parallel Processing Basics

When workflow steps are independent of each other, you can execute them in parallel to improve performance.

### 5.1 Independent Step Execution

Use `Promise.allSettled()` to run multiple steps simultaneously:

```typescript
protected override async *run_impl(): AsyncGenerator<any, WORKFLOW_OUTPUT, never> {
  const dto = await this.get_dto();
  const { documentText, analysisOptions } = dto.data;

  yield {
    type: "INTERNAL_UPDATE",
    message: "Starting parallel processing of independent analysis steps",
    metadata: { parallelSteps: 3 }
  };

  // Create multiple independent steps
  const sentimentAnalyzer = await this.appendOrRetrieveCall(
    SentimentAnalysisStep,
    "sentiment_analysis",
    { 
      input: documentText,
      options: analysisOptions.sentiment
    }
  );

  const topicExtractor = await this.appendOrRetrieveCall(
    TopicExtractionStep,
    "topic_extraction",
    { 
      input: documentText,
      options: analysisOptions.topics
    }
  );

  const keywordAnalyzer = await this.appendOrRetrieveCall(
    KeywordAnalysisStep,
    "keyword_analysis",
    { 
      input: documentText,
      options: analysisOptions.keywords
    }
  );

  // Execute all steps in parallel
  const results = await Promise.allSettled([
    sentimentAnalyzer.run(),
    topicExtractor.run(),
    keywordAnalyzer.run()
  ]);

  yield {
    type: "INTERNAL_UPDATE",
    message: "Parallel processing completed",
    metadata: { 
      completedSteps: results.filter(r => r.status === 'fulfilled').length,
      failedSteps: results.filter(r => r.status === 'rejected').length
    }
  };

  // Process results
  const sentimentResult = results[0].status === 'fulfilled' ? results[0].value : null;
  const topicResult = results[1].status === 'fulfilled' ? results[1].value : null;
  const keywordResult = results[2].status === 'fulfilled' ? results[2].value : null;

  // Handle any failures
  const errors = results
    .filter(result => result.status === 'rejected')
    .map((result, index) => ({
      step: ['sentiment', 'topics', 'keywords'][index],
      error: result.reason?.message || 'Unknown error'
    }));

  return {
    success: errors.length === 0,
    analysis: {
      sentiment: sentimentResult?.sentiment,
      confidence: sentimentResult?.confidence,
      topics: topicResult?.topics || [],
      keywords: keywordResult?.keywords || [],
      topicConfidence: topicResult?.confidence,
      keywordConfidence: keywordResult?.confidence
    },
    metadata: {
      parallelStepsRun: 3,
      successfulSteps: results.filter(r => r.status === 'fulfilled').length,
      failedSteps: errors.length
    },
    errors: errors.length > 0 ? errors : undefined
  };
}
```

### When to Use Parallel Processing

Parallel processing is effective when:
- **Steps are independent** - No step depends on another's output
- **Performance is important** - Total execution time matters
- **Resources allow** - System can handle concurrent operations
- **Steps have similar duration** - Avoid one slow step blocking others

### Note on Progress Streaming: 
The parallel execution pattern shown above uses the .run() method, which returns a Promise of the final result. This is efficient for performance but does not stream INTERNAL_UPDATE progress events from the parallel steps. For advanced use cases that require aggregating progress streams from parallel workflows, please refer to our dedicated "Advanced Parallelism Guide."

### 5.2 Mixed Serial and Parallel Patterns

Real workflows often combine serial and parallel execution:

```typescript
protected override async *run_impl(): AsyncGenerator<any, WORKFLOW_OUTPUT, never> {
  const dto = await this.get_dto();

  // Phase 1: Sequential preprocessing (required foundation)
  const preprocessor = await this.appendOrRetrieveCall(
    PreprocessorStep,
    "preprocessing",
    { input: dto.data.rawData }
  );
  const preprocessedData = yield* await preprocessor.start();

  // Phase 2: Parallel analysis (independent analyses of preprocessed data)
  const statisticalAnalyzer = await this.appendOrRetrieveCall(
    StatisticalAnalysisStep,
    "statistical",
    { input: preprocessedData.cleanData }
  );

  const patternAnalyzer = await this.appendOrRetrieveCall(
    PatternAnalysisStep,
    "patterns",
    { input: preprocessedData.cleanData }
  );

  const anomalyDetector = await this.appendOrRetrieveCall(
    AnomalyDetectionStep,
    "anomalies",
    { input: preprocessedData.cleanData }
  );

  // Run analyses in parallel
  const analysisResults = await Promise.allSettled([
    statisticalAnalyzer.run(),
    patternAnalyzer.run(),
    anomalyDetector.run()
  ]);

  // Phase 3: Sequential synthesis (combine parallel results)
  const synthesizer = await this.appendOrRetrieveCall(
    SynthesisStep,
    "synthesis",
    {
      statisticalResults: analysisResults[0].status === 'fulfilled' ? analysisResults[0].value : null,
      patternResults: analysisResults[1].status === 'fulfilled' ? analysisResults[1].value : null,
      anomalyResults: analysisResults[2].status === 'fulfilled' ? analysisResults[2].value : null,
      originalData: preprocessedData
    }
  );
  const finalReport = yield* await synthesizer.start();

  return {
    success: true,
    preprocessing: {
      recordsProcessed: preprocessedData.recordCount,
      cleaningApplied: preprocessedData.cleaningSteps
    },
    analysis: {
      statisticalSummary: analysisResults[0].status === 'fulfilled' ? analysisResults[0].value.summary : null,
      patternsFound: analysisResults[1].status === 'fulfilled' ? analysisResults[1].value.patterns?.length : 0,
      anomaliesDetected: analysisResults[2].status === 'fulfilled' ? analysisResults[2].value.anomalies?.length : 0
    },
    report: finalReport.document,
    metadata: finalReport.metadata
  };
}
```

### Fan-Out/Fan-In Pattern

A common pattern where one step's output feeds multiple parallel steps, then results are combined:

```typescript
// Fan-out: One input, multiple parallel processors
const baseAnalysis = yield* await baseAnalyzer.start();

const processors = [
  { class: ProcessorA, name: "processor_a", config: { mode: 'detailed' } },
  { class: ProcessorB, name: "processor_b", config: { mode: 'summary' } },
  { class: ProcessorC, name: "processor_c", config: { mode: 'visual' } }
];

// Create all processors
const processorPromises = processors.map(async (proc) => {
  const processor = await this.appendOrRetrieveCall(
    proc.class,
    proc.name,
    { 
      input: baseAnalysis.data,
      config: proc.config
    }
  );
  return processor.run();
});

// Execute in parallel
const processorResults = await Promise.allSettled(processorPromises);

// Fan-in: Combine all results
const combiner = await this.appendOrRetrieveCall(
  ResultCombinerStep,
  "combiner",
  {
    baseAnalysis: baseAnalysis,
    processorResults: processorResults.map((result, index) => ({
      processor: processors[index].name,
      success: result.status === 'fulfilled',
      result: result.status === 'fulfilled' ? result.value : null,
      error: result.status === 'rejected' ? result.reason : null
    }))
  }
);

const combinedResult = yield* await combiner.start();
```

## 6. Step Types and Patterns

Understanding different types of steps helps you design effective workflows. Each step type has specific characteristics and use cases.

### 6.1 Orchestration Steps

These are "pure coordinators" that manage other steps but don't perform direct AI or external work themselves.

```typescript
@RunnableEntityDecorator({
  generalType: "OrchestrationStep",
  specificType: "DataProcessingOrchestrator",
  allowedConnections: {
    'Calls': ['DataValidatorStep', 'DataTransformerStep', 'DataAnalyzerStep', 'ReportGeneratorStep']
  }
})
export class DataProcessingOrchestrator extends RunnableEntityClass {
  
  protected override async *run_impl(): AsyncGenerator<any, any, never> {
    const dto = await this.get_dto();
    const { inputData, processingOptions } = dto.data;

    // This step only coordinates - no AI or external calls
    
    // Step 1: Validate input
    if (processingOptions.validateInput) {
      const validator = await this.appendOrRetrieveCall(
        DataValidatorStep,
        "validation",
        { input: inputData }
      );
      const validationResult = yield* await validator.start();
      
      if (!validationResult.isValid) {
        return { success: false, errors: validationResult.errors };
      }
    }

    // Step 2: Transform data
    const transformer = await this.appendOrRetrieveCall(
      DataTransformerStep,
      "transformation",
      { 
        input: inputData,
        transformations: processingOptions.transformations
      }
    );
    const transformedData = yield* await transformer.start();

    // Step 3: Conditional analysis
    let analysisResult = null;
    if (processingOptions.runAnalysis) {
      const analyzer = await this.appendOrRetrieveCall(
        DataAnalyzerStep,
        "analysis",
        { input: transformedData.data }
      );
      analysisResult = yield* await analyzer.start();
    }

    // Step 4: Generate report
    const reportGenerator = await this.appendOrRetrieveCall(
      ReportGeneratorStep,
      "report",
      {
        data: transformedData.data,
        analysis: analysisResult,
        options: processingOptions.reportOptions
      }
    );
    const report = yield* await reportGenerator.start();

    return {
      success: true,
      processedRecords: transformedData.recordCount,
      analysisPerformed: !!analysisResult,
      report: report.document,
      metadata: {
        validationPerformed: processingOptions.validateInput,
        transformationsApplied: processingOptions.transformations.length,
        reportFormat: processingOptions.reportOptions.format
      }
    };
  }
}
```

**Characteristics of Orchestration Steps:**
- **No direct AI calls** - Delegates AI work to specialized steps
- **Complex business logic** - Handles conditional execution, loops, parallel processing
- **State management** - Coordinates data flow between steps
- **Progress tracking** - Provides meaningful updates about workflow progress

### 6.2 Bot-Wrapped Steps

These steps wrap bots to provide AI-powered processing with structured outputs:

```typescript
@RunnableEntityBotWrapperDecorator(
  {
    generalType: "ProcessingStep",
    specificType: "DocumentAnalysisStep",
    allowedConnections: {}
  },
  new DocumentAnalysisBot()
)
export class DocumentAnalysisStep extends RunnableEntityBotWrapperClass {
  
  protected override async get_bot_request_args(): Promise<BotRequestArgs<any>> {
    const dto = await this.get_dto();
    const { documentText, analysisType, previousResults } = dto.data;

    return {
      id: "document_analysis_request",
      args: {
        analysisType: analysisType,
        includeConfidence: true,
        previousContext: previousResults
      },
      input: documentText,
      context: new Context(dto),
      parent: undefined
    };
  }
}
```

**Characteristics of Bot-Wrapped Steps:**
- **Single responsibility** - Each step has one clear AI task
- **Structured input/output** - Well-defined interfaces for workflow integration
- **Context building** - Transforms workflow data into bot-friendly formats
- **Error handling** - Built-in retry and error recovery through bot framework

### 6.3 Waitable Steps (Human-in-the-Loop)

These steps pause execution to wait for human input:

```typescript
@WaitableRunnableEntityDecorator({
  generalType: "ProcessingStep", 
  specificType: "ReviewStep",
  allowedConnections: {}
})
export class ReviewStep extends WaitableRunnableEntityClass {
  
  protected override async *run_impl(): RunnableEntityResponseGenerator {
    const dto = await this.get_dto();
    const { documentToReview, reviewCriteria } = dto.data;
    
    // Wait for human review
    const message = yield this.createWaitingEnvelope(
      "Please review the processed document and provide feedback.",
      {
        document: documentToReview,
        criteria: reviewCriteria,
        options: ['approve', 'reject', 'request_changes']
      }
    );
    
    // Process the human response
    if (message.message === 'approved') {
      return { 
        approved: true, 
        feedback: null,
        nextAction: 'proceed'
      };
    } else if (message.message === 'rejected') {
      return { 
        approved: false, 
        feedback: message.data.reason,
        nextAction: 'terminate'
      };
    } else {
      return { 
        approved: false, 
        feedback: message.data.changes,
        nextAction: 'revise'
      };
    }
  }
  
  // External API methods for human interaction
  public approve() {
    this.sendMessage('approved', true);
  }
  
  public reject(reason: string) {
    this.sendMessage('rejected', { reason });
  }
  
  public requestChanges(changes: string) {
    this.sendMessage('request_changes', { changes });
  }
}
```

**Characteristics of Waitable Steps:**
- **External interaction** - Designed for human or external system input
- **State persistence** - Can wait indefinitely while maintaining state
- **Clear interfaces** - Well-defined methods for external interaction
- **Status visibility** - Clear indication when waiting for input

### 6.4 Arbitrary Processing Steps

These handle custom logic like file processing, API calls, calculations, or data transformations:

```typescript
@RunnableEntityDecorator({
  generalType: "ProcessingStep",
  specificType: "FileProcessorStep", 
  allowedConnections: {}
})
export class FileProcessorStep extends RunnableEntityClass {
  
  protected override async *run_impl(): AsyncGenerator<any, any, never> {
    const dto = await this.get_dto();
    const { fileUrl, processingOptions } = dto.data;

    try {
      // Step 1: Download file
      yield {
        type: "INTERNAL_UPDATE",
        message: "Downloading file from URL",
        metadata: { stage: "download", url: fileUrl }
      };
      
      const response = await fetch(fileUrl);
      if (!response.ok) {
        throw new Error(`Failed to download file: ${response.statusText}`);
      }
      const fileBuffer = await response.arrayBuffer();
      
      // Step 2: Process based on file type
      yield {
        type: "INTERNAL_UPDATE",
        message: "Processing file content",
        metadata: { stage: "processing", sizeBytes: fileBuffer.byteLength }
      };
      
      let processedContent;
      const fileType = this.detectFileType(fileUrl, fileBuffer);
      
      switch (fileType) {
        case 'pdf':
          processedContent = await this.processPDF(fileBuffer);
          break;
        case 'image':
          processedContent = await this.processImage(fileBuffer);
          break;
        case 'text':
          processedContent = await this.processText(fileBuffer);
          break;
        default:
          throw new Error(`Unsupported file type: ${fileType}`);
      }
      
      // Step 3: Apply processing options
      if (processingOptions.extractMetadata) {
        processedContent.metadata = await this.extractMetadata(fileBuffer, fileType);
      }
      
      if (processingOptions.generateThumbnail && fileType === 'image') {
        processedContent.thumbnail = await this.generateThumbnail(fileBuffer);
      }
      
      yield {
        type: "INTERNAL_UPDATE",
        message: "File processing completed",
        metadata: { 
          stage: "completed",
          fileType: fileType,
          outputSize: JSON.stringify(processedContent).length
        }
      };
      
      return {
        success: true,
        fileType: fileType,
        originalSize: fileBuffer.byteLength,
        processedContent: processedContent,
        processingTime: Date.now() - startTime
      };
      
    } catch (error) {
      return {
        success: false,
        error: error.message,
        fileUrl: fileUrl
      };
    }
  }
  
  private detectFileType(url: string, buffer: ArrayBuffer): string {
    // File type detection logic
    const extension = url.split('.').pop()?.toLowerCase();
    // Could also examine buffer headers for more accurate detection
    if (['jpg', 'jpeg', 'png', 'gif'].includes(extension || '')) return 'image';
    if (extension === 'pdf') return 'pdf';
    return 'text';
  }
  
  private async processPDF(buffer: ArrayBuffer): Promise<any> {
    // PDF processing logic
    return { extractedText: "PDF content...", pages: 3 };
  }
  
  private async processImage(buffer: ArrayBuffer): Promise<any> {
    // Image processing logic  
    return { dimensions: { width: 800, height: 600 }, format: "JPEG" };
  }
  
  private async processText(buffer: ArrayBuffer): Promise<any> {
    // Text processing logic
    const text = new TextDecoder().decode(buffer);
    return { content: text, wordCount: text.split(/\s+/).length };
  }
}
```

**Other Arbitrary Processing Examples:**

```typescript
// API Integration Step
@RunnableEntityDecorator({
  generalType: "ProcessingStep",
  specificType: "APICallStep",
  allowedConnections: {}
})
export class APICallStep extends RunnableEntityClass {
  protected override async *run_impl(): AsyncGenerator<any, any, never> {
    const dto = await this.get_dto();
    const { apiEndpoint, requestData, retryOptions } = dto.data;
    
    // Implement API call with retry logic
    let attempts = 0;
    while (attempts < retryOptions.maxRetries) {
      try {
        const response = await fetch(apiEndpoint, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(requestData)
        });
        
        if (response.ok) {
          const data = await response.json();
          return { success: true, data, attempts: attempts + 1 };
        }
        
        throw new Error(`API call failed: ${response.statusText}`);
        
      } catch (error) {
        attempts++;
        if (attempts >= retryOptions.maxRetries) {
          return { success: false, error: error.message, attempts };
        }
        
        await new Promise(resolve => 
          setTimeout(resolve, retryOptions.backoffMs * attempts)
        );
      }
    }
  }
}

// Data Calculation Step
@RunnableEntityDecorator({
  generalType: "ProcessingStep", 
  specificType: "CalculationStep",
  allowedConnections: {}
})
export class CalculationStep extends RunnableEntityClass {
  protected override async *run_impl(): AsyncGenerator<any, any, never> {
    const dto = await this.get_dto();
    const { dataset, calculationType, parameters } = dto.data;
    
    yield {
      type: "INTERNAL_UPDATE",
      message: `Performing ${calculationType} calculation on ${dataset.length} records`
    };
    
    let result;
    switch (calculationType) {
      case 'statistical_summary':
        result = this.calculateStatistics(dataset, parameters);
        break;
      case 'correlation_analysis':
        result = this.calculateCorrelations(dataset, parameters);
        break;
      case 'trend_analysis':
        result = this.calculateTrends(dataset, parameters);
        break;
      default:
        throw new Error(`Unknown calculation type: ${calculationType}`);
    }
    
    return {
      calculationType,
      inputRecords: dataset.length,
      result,
      parameters
    };
  }
}
```

## 7. Nested Workflows (Brief Introduction)

Sometimes you need workflows that call other workflows, creating hierarchical processing structures.

### 7.1 Workflow Calling Workflow

A parent workflow can delegate major sections of work to specialized child workflows:

```typescript
@RunnableEntityDecorator({
  generalType: "MainWorkflow",
  specificType: "DocumentProcessingWorkflow",
  allowedConnections: {
    'Calls': ['DocumentPreprocessingWorkflow', 'DocumentAnalysisWorkflow', 'ReportGenerationWorkflow']
  }
})
export class DocumentProcessingWorkflow extends RunnableEntityClass {
  
  protected override async *run_impl(): AsyncGenerator<any, any, never> {
    const dto = await this.get_dto();
    const { documents, processingOptions } = dto.data;

    // Phase 1: Preprocessing workflow
    const preprocessingWF = await this.appendOrRetrieveCall(
      DocumentPreprocessingWorkflow,
      "preprocessing_workflow",
      {
        documents: documents,
        cleaningOptions: processingOptions.cleaning,
        validationOptions: processingOptions.validation
      }
    );
    const preprocessedDocuments = yield* await preprocessingWF.start();

    // Phase 2: Analysis workflow (only if preprocessing succeeded)
    if (!preprocessedDocuments.success) {
      return {
        success: false,
        phase: "preprocessing",
        error: preprocessedDocuments.error
      };
    }

    const analysisWF = await this.appendOrRetrieveCall(
      DocumentAnalysisWorkflow,
      "analysis_workflow", 
      {
        documents: preprocessedDocuments.processedDocuments,
        analysisTypes: processingOptions.analysisTypes,
        parallelProcessing: processingOptions.enableParallel
      }
    );
    const analysisResults = yield* await analysisWF.start();

    // Phase 3: Report generation workflow
    const reportWF = await this.appendOrRetrieveCall(
      ReportGenerationWorkflow,
      "report_workflow",
      {
        analysisResults: analysisResults,
        reportFormat: processingOptions.reportFormat,
        includeRawData: processingOptions.includeRawData
      }
    );
    const finalReport = yield* await reportWF.start();

    return {
      success: true,
      documentsProcessed: preprocessedDocuments.documentsProcessed,
      analysisTypesRun: analysisResults.analysisTypes?.length || 0,
      reportGenerated: finalReport.success,
      report: finalReport.report,
      metadata: {
        preprocessingTime: preprocessedDocuments.processingTime,
        analysisTime: analysisResults.processingTime,
        reportGenerationTime: finalReport.processingTime,
        totalTime: preprocessedDocuments.processingTime + 
                   analysisResults.processingTime + 
                   finalReport.processingTime
      }
    };
  }
}
```

### Child Workflow Example

Each child workflow handles a specific domain:

```typescript
@RunnableEntityDecorator({
  generalType: "SubWorkflow",
  specificType: "DocumentAnalysisWorkflow", 
  allowedConnections: {
    'Calls': ['SentimentAnalysisStep', 'TopicExtractionStep', 'SummaryGenerationStep']
  }
})
export class DocumentAnalysisWorkflow extends RunnableEntityClass {
  
  protected override async *run_impl(): AsyncGenerator<any, any, never> {
    const dto = await this.get_dto();
    const { documents, analysisTypes, parallelProcessing } = dto.data;

    const results = [];
    
    // This workflow specializes in document analysis orchestration
    for (const document of documents) {
      if (parallelProcessing) {
        // Run analyses in parallel for each document
        const analysisPromises = analysisTypes.map(async (analysisType: string) => {
          const stepName = `${analysisType}_${document.id}`;
          const stepClass = this.getAnalysisStepClass(analysisType);
          
          const step = await this.appendOrRetrieveCall(
            stepClass,
            stepName,
            { document: document.content, type: analysisType }
          );
          
          return await step.run();
        });
        
        const documentResults = await Promise.allSettled(analysisPromises);
        results.push({
          documentId: document.id,
          results: documentResults
        });
        
      } else {
        // Run analyses sequentially for each document
        const documentResults = [];
        
        for (const analysisType of analysisTypes) {
          const stepName = `${analysisType}_${document.id}`;
          const stepClass = this.getAnalysisStepClass(analysisType);
          
          const step = await this.appendOrRetrieveCall(
            stepClass,
            stepName,
            { document: document.content, type: analysisType }
          );
          
          const result = yield* await step.start();
          documentResults.push(result);
        }
        
        results.push({
          documentId: document.id,
          results: documentResults
        });
      }
    }

    return {
      success: true,
      documentsAnalyzed: documents.length,
      analysisTypes: analysisTypes,
      results: results,
      processingTime: Date.now() - startTime
    };
  }
  
  private getAnalysisStepClass(analysisType: string): any {
    const stepMap = {
      'sentiment': SentimentAnalysisStep,
      'topics': TopicExtractionStep,
      'summary': SummaryGenerationStep
    };
    
    return stepMap[analysisType] || SentimentAnalysisStep;
  }
}
```

### 7.2 Design Considerations

**When to Nest Workflows:**

```typescript
// ✅ Good reasons to create nested workflows:

// 1. Reusable sub-processes
// A document analysis workflow that's used by multiple parent workflows
const documentAnalysisWF = new DocumentAnalysisWorkflow();

// 2. Complex domain separation 
// Financial processing has many specialized steps
const financialProcessingWF = new FinancialProcessingWorkflow();
const complianceCheckWF = new ComplianceCheckWorkflow();

// 3. Different scaling requirements
// CPU-intensive analysis workflow vs. I/O-heavy data workflow
const dataIngestionWF = new DataIngestionWorkflow();  // I/O bound
const analyticsWF = new AnalyticsWorkflow();          // CPU bound

// ❌ Avoid nesting for:
// Simple sequences that could be regular steps
// Single-use workflows that won't be reused
// Over-engineering simple processes
```

**Data Flow Design:**

```typescript
// Parent workflow passes context and gets structured results
const childWorkflowInput = {
  // Required data
  inputData: parentData.processedInput,
  
  // Configuration
  options: {
    mode: 'detailed',
    parallelProcessing: true
  },
  
  // Context from parent
  parentWorkflowId: this.id,
  requestId: dto.data.requestId,
  userPreferences: dto.data.userPreferences
};

const childWorkflow = await this.appendOrRetrieveCall(
  SpecializedWorkflow,
  "specialized_processing",
  childWorkflowInput
);

const childResult = yield* await childWorkflow.start();

// Child workflow returns structured data the parent can use
// childResult = {
//   success: boolean,
//   results: ProcessedData[],
//   metadata: ProcessingMetadata,
//   errors?: ErrorInfo[]
// }
```

**Abstraction Levels:**

Consider the right level of abstraction for your workflows:

- **High-level workflows** - Business process orchestration
- **Mid-level workflows** - Domain-specific processing (document analysis, data transformation)
- **Low-level steps** - Individual operations (AI calls, API calls, calculations)

```typescript
// High-level: Business process
CustomerOnboardingWorkflow
├── DocumentCollectionWorkflow     // Mid-level: Document domain
│   ├── DocumentUploadStep         // Low-level: File operation
│   ├── DocumentValidationStep     // Low-level: Validation logic
│   └── DocumentAnalysisStep       // Low-level: AI operation
├── ComplianceCheckWorkflow        // Mid-level: Compliance domain
│   ├── KYCCheckStep              // Low-level: External API
│   ├── RiskAssessmentStep        // Low-level: AI operation
│   └── ComplianceReportStep      // Low-level: Report generation
└── AccountSetupWorkflow          // Mid-level: Account domain
    ├── AccountCreationStep       // Low-level: Database operation
    ├── PermissionSetupStep       // Low-level: Configuration
    └── WelcomeNotificationStep   // Low-level: Communication
```

## 8. Best Practices for Basic Orchestration

### 8.1 Design Principles

**Clear Responsibility**

Each step should have a single, well-defined purpose:

```typescript
// ✅ Good: Single responsibility
class EmailValidationStep extends RunnableEntityClass {
  // Only validates email formats and deliverability
}

class EmailSendingStep extends RunnableEntityClass {
  // Only sends emails using validated addresses
}

// ❌ Bad: Multiple responsibilities  
class EmailProcessingStep extends RunnableEntityClass {
  // Validates emails AND sends them AND logs results
}
```

**Idempotency**

Steps should be safely re-executable:

```typescript
protected override async *run_impl(): AsyncGenerator<any, any, never> {
  const dto = await this.get_dto();
  
  // ✅ Good: Check if work already done
  if (dto.data.processingCompleted) {
    return dto.data.result;
  }
  
  // Perform processing
  const result = await this.performWork(dto.data.input);
  
  // Mark as completed
  await this.update_data({
    ...dto.data,
    processingCompleted: true,
    result: result
  });
  
  return result;
}
```

**Progress Visibility**

Provide meaningful updates throughout execution:

```typescript
protected override async *run_impl(): AsyncGenerator<any, any, never> {
  const dto = await this.get_dto();
  const items = dto.data.itemsToProcess;
  
  yield {
    type: "INTERNAL_UPDATE",
    message: `Starting batch processing of ${items.length} items`,
    metadata: { 
      stage: "started",
      totalItems: items.length,
      estimatedDuration: items.length * 30 // seconds
    }
  };
  
  const results = [];
  
  for (let i = 0; i < items.length; i++) {
    // Processing...
    const itemResult = await this.processItem(items[i]);
    results.push(itemResult);
    
    // Progress update every 10 items or on completion
    if ((i + 1) % 10 === 0 || i === items.length - 1) {
      yield {
        type: "INTERNAL_UPDATE",
        message: `Processed ${i + 1} of ${items.length} items`,
        metadata: {
          stage: "processing",
          completed: i + 1,
          total: items.length,
          percentComplete: Math.round(((i + 1) / items.length) * 100),
          estimatedTimeRemaining: (items.length - i - 1) * 30
        }
      };
    }
  }
  
  yield {
    type: "INTERNAL_UPDATE", 
    message: "Batch processing completed successfully",
    metadata: {
      stage: "completed",
      totalProcessed: results.length,
      successCount: results.filter(r => r.success).length,
      errorCount: results.filter(r => !r.success).length
    }
  };
  
  return {
    success: true,
    results: results,
    summary: {
      totalItems: items.length,
      successful: results.filter(r => r.success).length,
      failed: results.filter(r => !r.success).length
    }
  };
}
```

### 8.2 Naming and Organization

**Descriptive Step Names**

Use names that clearly indicate purpose:

```typescript
// ✅ Good: Clear purpose
await this.appendOrRetrieveCall(DocumentValidatorStep, "document_validation", data);
await this.appendOrRetrieveCall(SentimentAnalysisStep, "sentiment_analysis", data);
await this.appendOrRetrieveCall(ReportGeneratorStep, "report_generation", data);

// ❌ Bad: Vague purpose
await this.appendOrRetrieveCall(Step1, "step_1", data);
await this.appendOrRetrieveCall(ProcessorStep, "processor", data);
await this.appendOrRetrieveCall(HandlerStep, "handler", data);
```

**Consistent Naming Patterns**

Establish and follow naming conventions:

```typescript
// Pattern: [Domain][Action]Step for step classes
class DocumentAnalysisStep extends RunnableEntityClass { }
class DocumentValidationStep extends RunnableEntityClass { }
class EmailDeliveryStep extends RunnableEntityClass { }

// Pattern: [action]_[identifier] for step names in workflows
await this.appendOrRetrieveCall(DocumentAnalysisStep, "analysis_primary_document", data);
await this.appendOrRetrieveCall(DocumentValidationStep, "validation_uploaded_docs", data);
await this.appendOrRetrieveCall(EmailDeliveryStep, "delivery_notification_email", data);

// Pattern: [WorkflowPurpose]Workflow for workflow classes
class CustomerOnboardingWorkflow extends RunnableEntityClass { }
class DocumentProcessingWorkflow extends RunnableEntityClass { }
class ReportGenerationWorkflow extends RunnableEntityClass { }
```

**Logical Grouping**

Organize related steps and workflows:

```typescript
// Group by business domain
src/
  workflows/
    customer/
      CustomerOnboardingWorkflow.ts
      CustomerDataUpdateWorkflow.ts
    document/  
      DocumentProcessingWorkflow.ts
      DocumentAnalysisWorkflow.ts
    reporting/
      ReportGenerationWorkflow.ts
      DataExportWorkflow.ts
  
  steps/
    validation/
      DocumentValidationStep.ts
      EmailValidationStep.ts
      DataValidationStep.ts
    analysis/
      SentimentAnalysisStep.ts
      TopicAnalysisStep.ts
      StatisticalAnalysisStep.ts
    integration/
      EmailDeliveryStep.ts
      APICallStep.ts
      FileUploadStep.ts
```

### 8.3 Performance Considerations

**Parallel vs. Serial Execution**

Choose the right pattern for your use case:

```typescript
// ✅ Use parallel for independent operations
const independentAnalyses = await Promise.allSettled([
  sentimentAnalyzer.run(),  // Independent
  topicExtractor.run(),     // Independent
  keywordAnalyzer.run()     // Independent
]);

// ✅ Use serial for dependent operations
const extractionResult = yield* await textExtractor.start();        // Must complete first
const analysisResult = yield* await analyzer.start(extractionResult); // Depends on extraction
const reportResult = yield* await reporter.start(analysisResult);     // Depends on analysis

// ⚠️ Consider mixed patterns for optimal performance
// Preprocess first (serial requirement)
const preprocessed = yield* await preprocessor.start();

// Then run independent analyses (parallel opportunity)
const analyses = await Promise.allSettled([
  statisticalAnalyzer.run(preprocessed),
  patternAnalyzer.run(preprocessed),
  anomalyDetector.run(preprocessed)
]);

// Finally synthesize results (serial requirement)
const final = yield* await synthesizer.start(analyses);
```

**Entity Creation Efficiency**

Be mindful of entity creation patterns:

```typescript
// ✅ Efficient: Reuse entities when appropriate
const processorStepName = `processor_${dto.data.processingType}`;
const processor = await this.appendOrRetrieveCall(
  ProcessorStep,
  processorStepName,  // Same name = same entity reused
  { type: dto.data.processingType }
);

// ⚠️ Less efficient: Creating many similar entities
for (let i = 0; i < 1000; i++) {
  // Creates 1000 separate entities - might be necessary but consider batch processing
  const itemProcessor = await this.appendOrRetrieveCall(
    ItemProcessor,
    `item_${i}`,
    { item: items[i] }
  );
}

// ✅ More efficient alternative: Batch processing
const batchProcessor = await this.appendOrRetrieveCall(
  BatchProcessor,
  "batch_processor",
  { items: items, batchSize: 50 }
);
```

### 8.4 Idempotency and Determinism: The Keys to Resumable Workflows

One of the most powerful features of the FireFoundry orchestration engine is its built-in support for resumability and reliability. This is achieved through the principles of **idempotency** and **determinism**. Understanding these concepts is essential for building robust, production-grade workflows.

**Idempotency: Safe to Re-run**

In FireFoundry, an operation is idempotent if running it multiple times has the same effect as running it once. The platform guarantees this at the level of individual workflow steps.

When you attempt to run a runnable entity that has already reached a `Completed` status, the platform **does not re-execute its `run_impl` logic**. Instead, it immediately returns the previously computed and persisted result.

This behavior is orchestrated by the `appendOrRetrieveCall` method. The unique step name you provide acts as the **idempotency key**:

```typescript
// The name "text_extraction_1" is the idempotency key for this step.
const textExtractor = await this.appendOrRetrieveCall(
  TextExtractorStep,
  "text_extraction_1", // <-- Idempotency Key
  { input: documentText }
);
const extractedText = yield* await textExtractor.start();
```

When a workflow runs, it checks for an entity with the name `"text_extraction_1"`.
*   If the step has already run to completion, `start()` returns its saved result instantly.
*   If the step has not been run, it is executed and its result is saved upon completion.
*   If the workflow fails at a later step (e.g., "analysis_1"), a re-run will find the completed `"text_extraction_1"` step, retrieve its result without re-execution, and proceed directly to the point of failure.

**Determinism: Your Part of the Contract**

While the platform provides idempotent building blocks, you are responsible for ensuring your orchestrator's logic is **deterministic**. A deterministic workflow, given the same inputs and the same results from its child steps, must always execute the same logic and call the same subsequent steps in the same order.

In practice, this means your `run_impl` method should not introduce unpredictable behavior. Its logic should be based solely on its input DTO and the results from its child steps.

**Handling Non-Determinism: The "Capture the Unpredictable" Pattern**

A common pitfall is introducing non-deterministic values—like random numbers or timestamps—directly inside an orchestrator's `run_impl` method.

**❌ Anti-Pattern: Uncaptured Randomness**

```typescript
protected override async *run_impl(): AsyncGenerator<any, any, never> {
  const dto = await this.get_dto();
  
  // BAD: This value is not captured. If the workflow fails after this line,
  // a re-run will generate a NEW random number, breaking consistency.
  const uniqueRequestId = `req-${Math.random()}`; 
  
  const stepA = await this.appendOrRetrieveCall(
    StepA,
    "step_a",
    { input: dto.data.input, requestId: uniqueRequestId } // Passing unpredictable value
  );
  
  // ... workflow continues
}
```

If this workflow fails after generating `uniqueRequestId` but before completing, a retry will generate a *different* random number, potentially leading to inconsistent state or duplicate processing in external systems.

**✅ Best Practice: Encapsulate and Persist Non-Determinism**

To handle this correctly, you must treat any non-deterministic operation as its own distinct workflow step. By encapsulating it in an entity, you capture its result and make it a stable, persisted part of your workflow's state.

First, create a simple entity whose sole job is to generate and return the unpredictable value:

```typescript
// A step that generates a random number once and persists it.
@RunnableEntityDecorator({ ... })
export class RandomNumberGeneratorStep extends RunnableEntityClass {
  protected override async *run_impl(): AsyncGenerator<any, number, never> {
    const randomNumber = Math.random();
    return randomNumber;
  }
}
```

Then, call this entity from your orchestrator:

```typescript
protected override async *run_impl(): AsyncGenerator<any, any, never> {
  const dto = await this.get_dto();
  
  // GOOD: The random number is generated and persisted by its own entity.
  const randomNumberGenerator = await this.appendOrRetrieveCall(
    RandomNumberGeneratorStep,
    "random_number_generation_1"
  );
  const randomNumber = yield* await randomNumberGenerator.start();
  
  // Now, randomNumber is a stable, persisted value.
  // Every re-run will retrieve the SAME value from the completed step.
  const uniqueRequestId = `req-${randomNumber}`;
  
  const stepA = await this.appendOrRetrieveCall(
    StepA,
    "step_a",
    { input: dto.data.input, requestId: uniqueRequestId }
  );
  
  // ... workflow continues deterministically
}
```

This pattern applies to any non-repeatable value:
*   Random numbers (`Math.random()`)
*   Current timestamps (`Date.now()`)
*   Unique IDs (`crypto.randomUUID()`)
*   Calls to volatile external APIs that might return different data on subsequent calls

By modeling every non-deterministic action as a distinct, idempotent step, you ensure your overall workflow remains perfectly deterministic, resumable, and reliable.

## 9. Simple Real-World Example: Content Analysis Workflow

Let's build a complete, realistic example that demonstrates the key orchestration patterns covered in this guide.

### 9.1 Business Requirements

We need a workflow that:
1. **Validates uploaded content** (text, documents, or URLs)
2. **Extracts and cleans text** from various input formats
3. **Analyzes content** based on user preferences (sentiment, topics, summary)
4. **Generates a formatted report** with the analysis results

The workflow should support:
- **Conditional processing** based on content type and user preferences
- **Parallel analysis** when multiple analysis types are requested
- **Progress tracking** throughout the process
- **Graceful error handling** if individual steps fail

### 9.2 Complete Implementation

**Step 1: Content Validation Step**

```typescript
@RunnableEntityDecorator({
  generalType: "Step",
  specificType: "ContentValidationStep",
  allowedConnections: {}
})
export class ContentValidationStep extends RunnableEntityClass {
  protected override async *run_impl(): AsyncGenerator<any, ValidationResult, never> {
    const dto = await this.get_dto();
    const { inputType, content, url, validationRules } = dto.data;
    
    yield {
      type: "INTERNAL_UPDATE",
      message: `Validating ${inputType} content`,
      metadata: { stage: "validation_start", inputType }
    };
    
    const result: ValidationResult = {
      isValid: true,
      errors: [],
      warnings: [],
      metadata: {}
    };
    
    // Validate based on input type
    switch (inputType) {
      case 'text':
        if (!content || content.trim().length === 0) {
          result.isValid = false;
          result.errors.push("Text content is empty");
        } else if (content.length < validationRules.minLength) {
          result.errors.push(`Text too short (${content.length} < ${validationRules.minLength})`);
          result.isValid = false;
        } else if (content.length > validationRules.maxLength) {
          result.warnings.push(`Text very long (${content.length} > ${validationRules.maxLength})`);
        }
        result.metadata.wordCount = content.split(/\s+/).length;
        break;
        
      case 'url':
        if (!url || !this.isValidUrl(url)) {
          result.isValid = false;
          result.errors.push("Invalid URL format");
        } else {
          // Check if URL is accessible
          try {
            const response = await fetch(url, { method: 'HEAD' });
            if (!response.ok) {
              result.warnings.push(`URL returned status ${response.status}`);
            }
            result.metadata.urlStatus = response.status;
          } catch (error) {
            result.isValid = false;
            result.errors.push(`URL not accessible: ${error.message}`);
          }
        }
        break;
        
      default:
        result.isValid = false;
        result.errors.push(`Unsupported input type: ${inputType}`);
    }
    
    yield {
      type: "INTERNAL_UPDATE",
      message: result.isValid ? "Content validation passed" : "Content validation failed",
      metadata: { 
        stage: "validation_complete",
        isValid: result.isValid,
        errorCount: result.errors.length,
        warningCount: result.warnings.length
      }
    };
    
    return result;
  }
  
  private isValidUrl(url: string): boolean {
    try {
      new URL(url);
      return true;
    } catch {
      return false;
    }
  }
}

interface ValidationResult {
  isValid: boolean;
  errors: string[];
  warnings: string[];
  metadata: Record<string, any>;
}
```

**Step 2: Text Extraction Step**

```typescript
@RunnableEntityDecorator({
  generalType: "Step", 
  specificType: "TextExtractionStep",
  allowedConnections: {}
})
export class TextExtractionStep extends RunnableEntityClass {
  protected override async *run_impl(): AsyncGenerator<any, ExtractionResult, never> {
    const dto = await this.get_dto();
    const { inputType, content, url, extractionOptions } = dto.data;
    
    let extractedText = "";
    let metadata = {};
    
    yield {
      type: "INTERNAL_UPDATE",
      message: `Extracting text from ${inputType}`,
      metadata: { stage: "extraction_start", inputType }
    };
    
    try {
      switch (inputType) {
        case 'text':
          extractedText = content;
          metadata = { originalLength: content.length };
          break;
          
        case 'url':
          yield {
            type: "INTERNAL_UPDATE",
            message: "Fetching content from URL",
            metadata: { stage: "url_fetch", url }
          };
          
          const response = await fetch(url);
          const html = await response.text();
          
          // Simple HTML text extraction (in production, use a proper HTML parser)
          extractedText = html.replace(/<[^>]*>/g, ' ')
                             .replace(/\s+/g, ' ')
                             .trim();
          
          metadata = { 
            originalHtmlLength: html.length,
            extractedLength: extractedText.length,
            url: url
          };
          break;
      }
      
      // Apply text cleaning if requested
      if (extractionOptions.cleanText) {
        yield {
          type: "INTERNAL_UPDATE", 
          message: "Cleaning extracted text",
          metadata: { stage: "text_cleaning" }
        };
        
        const originalLength = extractedText.length;
        extractedText = this.cleanText(extractedText);
        metadata.cleaningApplied = true;
        metadata.lengthAfterCleaning = extractedText.length;
        metadata.charactersRemoved = originalLength - extractedText.length;
      }
      
      yield {
        type: "INTERNAL_UPDATE",
        message: "Text extraction completed",
        metadata: { 
          stage: "extraction_complete",
          extractedLength: extractedText.length,
          wordCount: extractedText.split(/\s+/).length
        }
      };
      
      return {
        success: true,
        extractedText,
        metadata,
        wordCount: extractedText.split(/\s+/).length
      };
      
    } catch (error) {
      return {
        success: false,
        error: error.message,
        extractedText: "",
        metadata: {},
        wordCount: 0
      };
    }
  }
  
  private cleanText(text: string): string {
    return text
      // Remove multiple whitespace
      .replace(/\s+/g, ' ')
      // Remove special characters but keep basic punctuation
      .replace(/[^\w\s.,!?;:-]/g, '')
      // Trim
      .trim();
  }
}

interface ExtractionResult {
  success: boolean;
  extractedText: string;
  metadata: Record<string, any>;
  wordCount: number;
  error?: string;
}
```

**Step 3: Analysis Steps (Bot-wrapped)**

```typescript
// Sentiment Analysis Step
@RunnableEntityBotWrapperDecorator(
  {
    generalType: "Step",
    specificType: "SentimentAnalysisStep",
    allowedConnections: {}
  },
  new SentimentAnalysisBot()
)
export class SentimentAnalysisStep extends RunnableEntityBotWrapperClass {
  protected override async get_bot_request_args(): Promise<BotRequestArgs<any>> {
    const dto = await this.get_dto();
    const { text, options } = dto.data;
    
    return {
      id: "sentiment_analysis_request",
      args: { 
        includeConfidence: options?.includeConfidence || true,
        detailLevel: options?.detailLevel || 'standard'
      },
      input: text,
      context: new Context(dto),
      parent: undefined
    };
  }
}

// Topic Analysis Step
@RunnableEntityBotWrapperDecorator(
  {
    generalType: "Step",
    specificType: "TopicAnalysisStep", 
    allowedConnections: {}
  },
  new TopicAnalysisBot()
)
export class TopicAnalysisStep extends RunnableEntityBotWrapperClass {
  protected override async get_bot_request_args(): Promise<BotRequestArgs<any>> {
    const dto = await this.get_dto();
    const { text, options } = dto.data;
    
    return {
      id: "topic_analysis_request",
      args: { 
        maxTopics: options?.maxTopics || 5,
        includeKeywords: options?.includeKeywords || true
      },
      input: text,
      context: new Context(dto),
      parent: undefined
    };
  }
}

// Summary Generation Step
@RunnableEntityBotWrapperDecorator(
  {
    generalType: "Step",
    specificType: "SummaryGenerationStep",
    allowedConnections: {}
  },
  new SummaryGenerationBot()
)
export class SummaryGenerationStep extends RunnableEntityBotWrapperClass {
  protected override async get_bot_request_args(): Promise<BotRequestArgs<any>> {
    const dto = await this.get_dto();
    const { text, options } = dto.data;
    
    return {
      id: "summary_generation_request",
      args: { 
        length: options?.summaryLength || 'medium',
        style: options?.summaryStyle || 'informative'
      },
      input: text,
      context: new Context(dto),
      parent: undefined
    };
  }
}
```

**Step 4: Report Generation Step**

```typescript
@RunnableEntityDecorator({
  generalType: "Step",
  specificType: "ReportGenerationStep",
  allowedConnections: {}
})
export class ReportGenerationStep extends RunnableEntityClass {
  protected override async *run_impl(): AsyncGenerator<any, ReportResult, never> {
    const dto = await this.get_dto();
    const { 
      originalText, 
      analysisResults, 
      reportFormat, 
      includeRawData 
    } = dto.data;
    
    yield {
      type: "INTERNAL_UPDATE",
      message: `Generating ${reportFormat} report`,
      metadata: { stage: "report_generation_start", format: reportFormat }
    };
    
    try {
      let report = "";
      
      switch (reportFormat) {
        case 'json':
          report = JSON.stringify({
            metadata: {
              generatedAt: new Date().toISOString(),
              textLength: originalText.length,
              analysisTypes: Object.keys(analysisResults)
            },
            analysis: analysisResults,
            rawData: includeRawData ? { originalText } : undefined
          }, null, 2);
          break;
          
        case 'markdown':
          report = this.generateMarkdownReport(originalText, analysisResults, includeRawData);
          break;
          
        case 'html':
          report = this.generateHtmlReport(originalText, analysisResults, includeRawData);
          break;
          
        default:
          throw new Error(`Unsupported report format: ${reportFormat}`);
      }
      
      yield {
        type: "INTERNAL_UPDATE",
        message: "Report generation completed",
        metadata: { 
          stage: "report_generation_complete",
          reportLength: report.length,
          format: reportFormat
        }
      };
      
      return {
        success: true,
        report,
        format: reportFormat,
        metadata: {
          generatedAt: new Date().toISOString(),
          reportSize: report.length,
          analysisIncluded: Object.keys(analysisResults)
        }
      };
      
    } catch (error) {
      return {
        success: false,
        error: error.message,
        report: "",
        format: reportFormat,
        metadata: {}
      };
    }
  }
  
  private generateMarkdownReport(
    originalText: string, 
    analysisResults: any, 
    includeRawData: boolean
  ): string {
    let report = "# Content Analysis Report\n\n";
    report += `**Generated:** ${new Date().toISOString()}\n\n`;
    report += `**Original Text Length:** ${originalText.length} characters\n\n`;
    
    if (analysisResults.sentiment) {
      report += "## Sentiment Analysis\n\n";
      report += `**Sentiment:** ${analysisResults.sentiment.sentiment}\n`;
      report += `**Confidence:** ${(analysisResults.sentiment.confidence * 100).toFixed(1)}%\n\n`;
    }
    
    if (analysisResults.topics) {
      report += "## Topic Analysis\n\n";
      analysisResults.topics.topics.forEach((topic: string, index: number) => {
        report += `${index + 1}. ${topic}\n`;
      });
      report += "\n";
    }
    
    if (analysisResults.summary) {
      report += "## Summary\n\n";
      report += `${analysisResults.summary.summary}\n\n`;
    }
    
    if (includeRawData) {
      report += "## Original Text\n\n";
      report += "```\n";
      report += originalText.substring(0, 1000);
      if (originalText.length > 1000) {
        report += "\n... (truncated)";
      }
      report += "\n```\n";
    }
    
    return report;
  }
  
  private generateHtmlReport(
    originalText: string,
    analysisResults: any,
    includeRawData: boolean
  ): string {
    let html = `
      <!DOCTYPE html>
      <html>
      <head>
        <title>Content Analysis Report</title>
        <style>
          body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
          .metadata { background: #f5f5f5; padding: 15px; border-radius: 5px; margin-bottom: 20px; }
          .analysis-section { margin-bottom: 25px; }
          .confidence { color: #666; font-size: 0.9em; }
        </style>
      </head>
      <body>
        <h1>Content Analysis Report</h1>
        <div class="metadata">
          <strong>Generated:</strong> ${new Date().toISOString()}<br>
          <strong>Text Length:</strong> ${originalText.length} characters
        </div>
    `;
    
    if (analysisResults.sentiment) {
      html += `
        <div class="analysis-section">
          <h2>Sentiment Analysis</h2>
          <p><strong>Sentiment:</strong> ${analysisResults.sentiment.sentiment}</p>
          <p class="confidence">Confidence: ${(analysisResults.sentiment.confidence * 100).toFixed(1)}%</p>
        </div>
      `;
    }
    
    if (analysisResults.topics) {
      html += `
        <div class="analysis-section">
          <h2>Topics</h2>
          <ul>
      `;
      analysisResults.topics.topics.forEach((topic: string) => {
        html += `<li>${topic}</li>`;
      });
      html += `
          </ul>
        </div>
      `;
    }
    
    if (analysisResults.summary) {
      html += `
        <div class="analysis-section">
          <h2>Summary</h2>
          <p>${analysisResults.summary.summary}</p>
        </div>
      `;
    }
    
    html += `
      </body>
      </html>
    `;
    
    return html;
  }
}

interface ReportResult {
  success: boolean;
  report: string;
  format: string;
  metadata: Record<string, any>;
  error?: string;
}
```

**Main Workflow Implementation**

```typescript
@RunnableEntityDecorator({
  generalType: "Workflow",
  specificType: "ContentAnalysisWorkflow",
  allowedConnections: {
    'Calls': [
      'ContentValidationStep', 
      'TextExtractionStep', 
      'SentimentAnalysisStep',
      'TopicAnalysisStep',
      'SummaryGenerationStep', 
      'ReportGenerationStep'
    ]
  }
})
export class ContentAnalysisWorkflow extends RunnableEntityClass {
  
  protected override async *run_impl(): AsyncGenerator<any, ContentAnalysisResult, never> {
    const startTime = Date.now();
    const dto = await this.get_dto();
    const { 
      inputType, 
      content, 
      url, 
      analysisOptions, 
      reportOptions 
    } = dto.data;
    
    yield {
      type: "INTERNAL_UPDATE",
      message: "Starting content analysis workflow",
      metadata: { 
        stage: "workflow_start",
        inputType,
        analysisTypes: analysisOptions.types,
        reportFormat: reportOptions.format
      }
    };
    
    try {
      // Step 1: Validate input
      const validator = await this.appendOrRetrieveCall(
        ContentValidationStep,
        "content_validation",
        {
          inputType,
          content,
          url,
          validationRules: {
            minLength: 10,
            maxLength: 100000
          }
        }
      );
      
      const validationResult = yield* await validator.start();
      
      if (!validationResult.isValid) {
        return {
          success: false,
          stage: "validation",
          errors: validationResult.errors,
          warnings: validationResult.warnings
        };
      }
      
      // Step 2: Extract text
      const extractor = await this.appendOrRetrieveCall(
        TextExtractionStep,
        "text_extraction",
        {
          inputType,
          content,
          url,
          extractionOptions: {
            cleanText: reportOptions.cleanText || true
          }
        }
      );
      
      const extractionResult = yield* await extractor.start();
      
      if (!extractionResult.success) {
        return {
          success: false,
          stage: "extraction",
          error: extractionResult.error
        };
      }
      
      // Step 3: Run analyses (parallel or serial based on preferences)
      const analysisResults: Record<string, any> = {};
      
      if (analysisOptions.parallel && analysisOptions.types.length > 1) {
        // Parallel execution
        yield {
          type: "INTERNAL_UPDATE",
          message: `Running ${analysisOptions.types.length} analyses in parallel`,
          metadata: { stage: "analysis_parallel", types: analysisOptions.types }
        };
        
        const analysisPromises = [];
        
        if (analysisOptions.types.includes('sentiment')) {
          const sentimentAnalyzer = await this.appendOrRetrieveCall(
            SentimentAnalysisStep,
            "sentiment_analysis",
            { text: extractionResult.extractedText, options: analysisOptions.sentiment }
          );
          analysisPromises.push({
            type: 'sentiment',
            promise: sentimentAnalyzer.run()
          });
        }
        
        if (analysisOptions.types.includes('topics')) {
          const topicAnalyzer = await this.appendOrRetrieveCall(
            TopicAnalysisStep,
            "topic_analysis", 
            { text: extractionResult.extractedText, options: analysisOptions.topics }
          );
          analysisPromises.push({
            type: 'topics',
            promise: topicAnalyzer.run()
          });
        }
        
        if (analysisOptions.types.includes('summary')) {
          const summaryGenerator = await this.appendOrRetrieveCall(
            SummaryGenerationStep,
            "summary_generation",
            { text: extractionResult.extractedText, options: analysisOptions.summary }
          );
          analysisPromises.push({
            type: 'summary',
            promise: summaryGenerator.run()
          });
        }
        
        // Execute all analyses in parallel
        const results = await Promise.allSettled(
          analysisPromises.map(ap => ap.promise)
        );
        
        // Process results
        results.forEach((result, index) => {
          const analysisType = analysisPromises[index].type;
          if (result.status === 'fulfilled') {
            analysisResults[analysisType] = result.value;
          } else {
            analysisResults[analysisType] = { 
              error: result.reason?.message || 'Analysis failed' 
            };
          }
        });
        
      } else {
        // Serial execution
        yield {
          type: "INTERNAL_UPDATE",
          message: `Running ${analysisOptions.types.length} analyses sequentially`,
          metadata: { stage: "analysis_serial", types: analysisOptions.types }
        };
        
        for (const analysisType of analysisOptions.types) {
          try {
            let analyzer;
            let stepName;
            let stepOptions;
            
            switch (analysisType) {
              case 'sentiment':
                analyzer = SentimentAnalysisStep;
                stepName = "sentiment_analysis";
                stepOptions = analysisOptions.sentiment;
                break;
              case 'topics':
                analyzer = TopicAnalysisStep;
                stepName = "topic_analysis";
                stepOptions = analysisOptions.topics;
                break;
              case 'summary':
                analyzer = SummaryGenerationStep;
                stepName = "summary_generation";
                stepOptions = analysisOptions.summary;
                break;
              default:
                continue;
            }
            
            const step = await this.appendOrRetrieveCall(
              analyzer,
              stepName,
              { text: extractionResult.extractedText, options: stepOptions }
            );
            
            analysisResults[analysisType] = yield* await step.start();
            
          } catch (error) {
            analysisResults[analysisType] = { 
              error: error.message || 'Analysis failed' 
            };
          }
        }
      }
      
      // Step 4: Generate report
      const reportGenerator = await this.appendOrRetrieveCall(
        ReportGenerationStep,
        "report_generation",
        {
          originalText: extractionResult.extractedText,
          analysisResults,
          reportFormat: reportOptions.format || 'json',
          includeRawData: reportOptions.includeRawData || false
        }
      );
      
      const reportResult = yield* await reportGenerator.start();
      
      const processingTime = Date.now() - startTime;
      
      yield {
        type: "INTERNAL_UPDATE",
        message: "Content analysis workflow completed successfully",
        metadata: { 
          stage: "workflow_complete",
          processingTime,
          analysisTypes: Object.keys(analysisResults),
          reportGenerated: reportResult.success
        }
      };
      
      return {
        success: true,
        textLength: extractionResult.wordCount,
        analysisResults,
        report: reportResult.report,
        reportFormat: reportResult.format,
        processingTime,
        metadata: {
          validationWarnings: validationResult.warnings,
          extractionMetadata: extractionResult.metadata,
          reportMetadata: reportResult.metadata,
          analysisExecutionMode: analysisOptions.parallel ? 'parallel' : 'serial'
        }
      };
      
    } catch (error) {
      return {
        success: false,
        stage: "workflow",
        error: error.message,
        processingTime: Date.now() - startTime
      };
    }
  }
}

interface ContentAnalysisResult {
  success: boolean;
  stage?: string;
  textLength?: number;
  analysisResults?: Record<string, any>;
  report?: string;
  reportFormat?: string;
  processingTime?: number;
  metadata?: Record<string, any>;
  errors?: string[];
  warnings?: string[];
  error?: string;
}
```

### 9.3 Pattern Analysis

This example demonstrates all the key orchestration patterns covered in this guide:

**Linear Processing (Steps 1-2)**
- Validation → Extraction follows a clear sequential dependency
- Each step's output becomes input for the next step

**Conditional Execution**
- Analysis steps only run if validation passes
- Different analysis types based on user preferences
- Report generation depends on successful analysis

**Parallel vs. Serial Processing** 
- User can choose parallel execution for independent analyses
- Demonstrates `Promise.allSettled()` pattern for parallel steps
- Falls back to serial execution when preferred

**Mixed Step Types**
- **Validation/Extraction** - Arbitrary processing steps
- **Analysis steps** - Bot-wrapped AI processing
- **Report generation** - Custom formatting logic
- **Main workflow** - Pure orchestration with business logic

**Progress Tracking**
- Meaningful status updates at each stage
- Detailed metadata about processing progress
- Clear indication of current workflow phase

**Data Flow Management**
- Clean output → input chaining between steps
- Structured result aggregation
- Comprehensive final output with metadata

**Error Handling**
- Validation failures stop execution early
- Individual analysis failures don't break entire workflow
- Clear error reporting with stage information

### 9.4 Usage Example

```typescript
// Create and run the workflow
const factory = createEntityFactory(MyConstructors);

const workflow = await factory.create_entity_node({
  specific_type_name: "ContentAnalysisWorkflow",
  general_type_name: "Workflow",
  data: {
    inputType: "url",
    url: "https://example.com/article",
    analysisOptions: {
      types: ['sentiment', 'topics', 'summary'],
      parallel: true,
      sentiment: { includeConfidence: true },
      topics: { maxTopics: 5 },
      summary: { length: 'medium' }
    },
    reportOptions: {
      format: 'html',
      includeRawData: false,
      cleanText: true
    }
  }
}) as ContentAnalysisWorkflow;

// Execute with progress tracking
const progressIterator = await workflow.start();

for await (const progress of progressIterator) {
  if (progress.type === 'INTERNAL_UPDATE') {
    console.log(`Progress: ${progress.message}`, progress.metadata);
  } else if (progress.type === 'COMPLETED') {
    console.log('Final result:', progress.value);
    break;
  }
}

// Alternative: Simple execution without progress tracking
const result = await workflow.run();

if (result.success) {
  console.log('Analysis completed successfully!');
  console.log(`Processed ${result.textLength} words in ${result.processingTime}ms`);
  console.log('Report generated:', result.reportFormat);
  
  // Save or display the report
  if (result.reportFormat === 'html') {
    // Save HTML report to file or display in browser
    await saveReportToFile(result.report, 'analysis-report.html');
  }
} else {
  console.log('Analysis failed:', result.error);
  console.log('Failed at stage:', result.stage);
}
```

This example shows how the workflow can handle different types of content, run analyses in parallel or serial based on preferences, and generate formatted reports - all while providing clear progress updates and error handling.

## 10. Common Patterns and Next Steps

### 10.1 Graduating to Advanced Patterns

As your orchestration needs grow more sophisticated, you may encounter scenarios where the basic patterns covered in this guide aren't sufficient. Here are indicators that you need more advanced approaches:

**When You Need Human-in-the-Loop**
```typescript
// Basic pattern works for automated workflows
const result = yield* await processor.start();

// But when you need human approval or feedback:
// ✅ Time to learn waitable entities
const reviewStep = await this.appendOrRetrieveCall(ReviewStep, "review", data);
const reviewResult = yield* await reviewStep.start(); // May wait indefinitely

if (reviewResult.approved) {
  // Continue workflow
} else {
  // Handle feedback and iterate
}
```

**When You Need Sophisticated Error Recovery**
```typescript
// Basic pattern handles simple errors
try {
  const result = yield* await processor.start();
} catch (error) {
  return { success: false, error: error.message };
}

// But when you need retry strategies, error classification, or recovery workflows:
// ✅ Time to learn advanced error handling patterns
const processor = await this.createProcessorWithRetryLogic();
const result = yield* await processor.startWithErrorRecovery();
```

**When You Need Complex External Integrations**
```typescript
// Basic pattern works for simple API calls
const apiResult = await fetch(endpoint, options);

// But when you need webhook coordination, file synchronization, or complex protocols:
// ✅ Time to learn external system integration patterns  
const externalWorkflow = await this.createExternalIntegrationWorkflow();
const result = yield* await externalWorkflow.start();
```

**When You Need Cross-Application Coordination**
```typescript
// Basic pattern works within one application
const localEntity = await this.appendOrRetrieveCall(LocalStep, "step", data);

// But when you need to coordinate with other Agent Bundles:
// ✅ Time to learn cross-app integration patterns
const remoteResult = await this.callRemoteAgentBundle('other-app', 'process', data);
```

### 10.2 Integration with Other Features

**Working Memory Usage**
While this guide focused on data flow through entity properties, many workflows need file handling:

```typescript
// Basic data flow (covered in this guide)
const textData = extractionResult.extractedText;
const processor = await this.appendOrRetrieveCall(TextProcessor, "processor", { text: textData });

// File-based workflows (see Working Memory guide)
const fileProcessor = await this.appendOrRetrieveCall(FileProcessor, "processor", {
  inputFilePath: "uploads/document.pdf",
  outputPath: "processed/analysis.json"
});
```

**Entity Graph Navigation**
This guide used simple data access, but complex workflows often need related entity data:

```typescript
// Basic data access (covered in this guide)  
const dto = await this.get_dto();
const inputData = dto.data.userInput;

// Graph navigation (see Entity Graph guides)
const relatedCompany = await this.getRelatedCompany();
const companyRequirements = await company.getRequirementsForDivision('default');
const contextData = { ...inputData, requirements: companyRequirements };
```

**Vector Similarity Integration**
For content analysis workflows, semantic search can enhance processing:

```typescript
// Basic content processing (covered in this guide)
const analysisResult = yield* await analyzer.start();

// With semantic search (see Vector Similarity guide)
const similarContent = await entity.find_similar(10, 0.7);
const enhancedAnalysis = await this.appendOrRetrieveCall(
  EnhancedAnalyzer,
  "enhanced_analysis",
  { content: analysisResult, similarExamples: similarContent }
);
```

### 10.3 Architectural Evolution

**Starting Simple and Growing**

Most successful workflow systems start simple and evolve:

1. **Single Linear Workflow** - A → B → C processing
2. **Add Conditionals** - Branch based on data or user preferences  
3. **Add Parallelism** - Speed up independent operations
4. **Add Human Review** - Critical approval points
5. **Add Error Recovery** - Sophisticated retry and failure handling
6. **Add Cross-System Integration** - External APIs and services
7. **Add Cross-App Coordination** - Multiple Agent Bundle orchestration

**Example Evolution Path:**

```typescript
// Version 1: Simple document processing
DocumentWorkflow: Upload → Extract → Analyze → Report

// Version 2: Add user preferences
DocumentWorkflow: Upload → Extract → [Conditional Analysis] → Report

// Version 3: Add parallel processing  
DocumentWorkflow: Upload → Extract → [Parallel Analyses] → Synthesize → Report

// Version 4: Add human review
DocumentWorkflow: Upload → Extract → Analyze → [Human Review] → Report

// Version 5: Add error recovery
DocumentWorkflow: Upload → [Retry Extract] → Analyze → Review → [Retry Report] → Complete

// Version 6: Add external systems
DocumentWorkflow: Upload → Extract → Analyze → Review → Report → [External Upload]

// Version 7: Add cross-app coordination
DocumentWorkflow: Upload → Extract → [Call Analytics App] → [Call Compliance App] → Report
```

### 10.4 Performance and Scalability Considerations

**Optimizing Workflow Performance**

```typescript
// ✅ Good: Minimize entity creation
const batchProcessor = await this.appendOrRetrieveCall(
  BatchProcessor,
  "batch_processor", 
  { items: largeItemArray, batchSize: 50 }
);

// ❌ Less optimal: Creating many entities
for (const item of largeItemArray) {
  const itemProcessor = await this.appendOrRetrieveCall(ItemProcessor, `item_${item.id}`, item);
}

// ✅ Good: Use parallel processing for independent work
const results = await Promise.allSettled([
  analyzer1.run(),
  analyzer2.run(), 
  analyzer3.run()
]);

// ✅ Good: Provide meaningful progress updates
yield {
  type: "INTERNAL_UPDATE",
  message: `Processing batch ${batchIndex + 1} of ${totalBatches}`,
  metadata: { 
    progress: Math.round((batchIndex / totalBatches) * 100),
    estimatedTimeRemaining: (totalBatches - batchIndex) * averageBatchTime
  }
};
```

**Monitoring and Observability**

```typescript
// Add workflow-level monitoring
protected override async *run_impl(): AsyncGenerator<any, any, never> {
  const startTime = Date.now();
  const dto = await this.get_dto();
  
  // Emit workflow start event
  yield {
    type: "WORKFLOW_EVENT",
    event: "workflow_started",
    metadata: {
      workflowType: this.constructor.name,
      workflowId: this.id,
      inputSize: JSON.stringify(dto.data).length,
      timestamp: new Date().toISOString()
    }
  };
  
  try {
    // Execute workflow steps...
    const result = yield* this.executeWorkflowSteps();
    
    // Emit success event
    yield {
      type: "WORKFLOW_EVENT", 
      event: "workflow_completed",
      metadata: {
        workflowId: this.id,
        duration: Date.now() - startTime,
        success: true,
        outputSize: JSON.stringify(result).length
      }
    };
    
    return result;
    
  } catch (error) {
    // Emit failure event
    yield {
      type: "WORKFLOW_EVENT",
      event: "workflow_failed", 
      metadata: {
        workflowId: this.id,
        duration: Date.now() - startTime,
        error: error.message,
        stage: this.getCurrentStage()
      }
    };
    
    throw error;
  }
}
```

## 11. Conclusion

This guide has covered the fundamental patterns for multi-step workflow orchestration in FireFoundry Agent Bundles. By mastering these basic building blocks, you can create sophisticated, maintainable workflows that coordinate AI processing, human input, and business logic.

### Key Takeaways

**Core Orchestration Patterns:**
- **Linear workflows** provide the foundation for sequential processing
- **Conditional execution** enables business logic and branching
- **Loop patterns** handle repetitive processing and convergence scenarios  
- **Parallel processing** improves performance for independent operations
- **Mixed patterns** combine serial and parallel execution optimally

**Step Design Principles:**
- **Single responsibility** - Each step has one clear purpose
- **Idempotency** - Steps can be safely re-executed
- **Progress visibility** - Clear status updates throughout execution
- **Clean data flow** - Well-defined input/output contracts

**Implementation Best Practices:**
- Use `appendOrRetrieveCall` for idempotent step creation
- Leverage `yield*` for progress delegation to child steps
- Design structured output schemas for reliable data flow
- Provide meaningful progress updates with metadata
- Handle errors gracefully at appropriate levels

**Architectural Patterns:**
- **Orchestration steps** coordinate other steps with business logic
- **Bot-wrapped steps** provide AI-powered processing with structured outputs
- **Waitable steps** enable human-in-the-loop workflows
- **Arbitrary processing steps** handle custom logic, file processing, and external APIs
- **Nested workflows** enable reusable sub-processes and complex hierarchies

### Building on These Foundations

The patterns covered in this guide provide a solid foundation for workflow orchestration, but they're just the beginning. As your needs grow more sophisticated, you can explore:

- **Advanced error handling and recovery strategies**
- **Human-in-the-loop patterns with waitable entities**
- **External system integration and API coordination**
- **Cross-application workflows and entity graph navigation**  
- **Working memory integration for file-based processing**
- **Vector similarity for semantic content processing**

### Getting Started

To begin building your own workflows:

1. **Start simple** with linear A → B → C patterns
2. **Add conditional logic** based on your business requirements
3. **Introduce parallelism** where operations are independent
4. **Design clear step interfaces** with well-defined inputs and outputs
5. **Implement comprehensive progress tracking** for visibility
6. **Test thoroughly** at both step and workflow levels
7. **Evolve gradually** as your requirements become more complex

The FireFoundry Agent Bundle SDK provides the tools and patterns to build workflows that scale from simple automation to complex, multi-step business processes. By following the principles and patterns in this guide, you can create maintainable, reliable orchestration systems that effectively coordinate AI processing with human oversight and business logic.

For more advanced patterns and specific integration scenarios, explore the other feature guides in the FireFoundry documentation.